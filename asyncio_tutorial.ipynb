{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Python's asyncio\n",
    "\n",
    "This notebook provides a comprehensive tutorial on Python's `asyncio` library, designed to teach you asynchronous programming concepts from the ground up.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction to Asynchronous Programming](#1-introduction-to-asynchronous-programming)\n",
    "2. [Asyncio Basics](#2-asyncio-basics)\n",
    "3. [Working with Tasks and Futures](#3-working-with-tasks-and-futures)\n",
    "4. [Advanced Asyncio Concepts](#4-advanced-asyncio-concepts)\n",
    "5. [Practical Examples](#5-practical-examples)\n",
    "6. [Best Practices and Patterns](#6-best-practices-and-patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Asynchronous Programming\n",
    "\n",
    "### What is Asynchronous Programming?\n",
    "\n",
    "Asynchronous programming is a programming paradigm that allows multiple operations to be executed concurrently (not necessarily in parallel) without blocking the main execution thread. In contrast to synchronous programming where operations are executed sequentially, asynchronous programming enables non-blocking execution, making it ideal for I/O-bound operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous vs. Asynchronous: A Practical Example\n",
    "\n",
    "Let's compare synchronous and asynchronous approaches to understand the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Synchronous function to simulate an I/O operation\n",
    "def sync_io_operation(operation_name, duration):\n",
    "    print(f\"Starting {operation_name}...\")\n",
    "    time.sleep(duration)  # Blocking operation\n",
    "    print(f\"Finished {operation_name} after {duration}s\")\n",
    "    return f\"{operation_name} result\"\n",
    "\n",
    "# Simulating multiple synchronous operations\n",
    "def run_sync_operations():\n",
    "    start = time.time()\n",
    "    \n",
    "    result1 = sync_io_operation(\"Operation 1\", 2)\n",
    "    result2 = sync_io_operation(\"Operation 2\", 1)\n",
    "    result3 = sync_io_operation(\"Operation 3\", 3)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Total synchronous execution time: {end - start:.2f}s\")\n",
    "    return [result1, result2, result3]\n",
    "\n",
    "# Run the synchronous operations\n",
    "run_sync_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the same operations executed asynchronously using `asyncio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Asynchronous function to simulate an I/O operation\n",
    "async def async_io_operation(operation_name, duration):\n",
    "    print(f\"Starting {operation_name}...\")\n",
    "    await asyncio.sleep(duration)  # Non-blocking operation\n",
    "    print(f\"Finished {operation_name} after {duration}s\")\n",
    "    return f\"{operation_name} result\"\n",
    "\n",
    "# Simulating multiple asynchronous operations\n",
    "async def run_async_operations():\n",
    "    start = time.time()\n",
    "    \n",
    "    # Create tasks to run concurrently\n",
    "    task1 = asyncio.create_task(async_io_operation(\"Operation 1\", 2))\n",
    "    task2 = asyncio.create_task(async_io_operation(\"Operation 2\", 1))\n",
    "    task3 = asyncio.create_task(async_io_operation(\"Operation 3\", 3))\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = await asyncio.gather(task1, task2, task3)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Total asynchronous execution time: {end - start:.2f}s\")\n",
    "    return results\n",
    "\n",
    "# Run the asynchronous operations\n",
    "await run_async_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Practice!\n\nNow it's your turn to try the difference between synchronous and asynchronous code.\n\nComplete the following exercise to simulate downloading files of different sizes. The `download_file` function already simulates synchronous downloads. Your task is to:\n\n1. Complete the `async_download_file` function to make it asynchronous using `asyncio.sleep()`\n2. Complete the `download_all_async` function to download all files concurrently using `asyncio.gather()`\n3. Run both functions and compare the execution times",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import time\n\n# This function simulates a synchronous file download\ndef download_file(file_name, file_size):\n    print(f\"Started downloading {file_name} ({file_size}MB)...\")\n    time.sleep(file_size / 10)  # Simulate download time (1 second per 10MB)\n    print(f\"Finished downloading {file_name}\")\n    return f\"{file_name} - {file_size}MB\"\n\n# Complete this function to simulate asynchronous file download\nasync def async_download_file(file_name, file_size):\n    print(f\"Started downloading {file_name} ({file_size}MB)...\")\n    # TODO: Replace the line below with asyncio.sleep()\n    time.sleep(file_size / 10)  \n    print(f\"Finished downloading {file_name}\")\n    return f\"{file_name} - {file_size}MB\"\n\n# Synchronous download of all files\ndef download_all_sync(files):\n    start = time.time()\n    results = []\n    \n    for file_name, file_size in files:\n        result = download_file(file_name, file_size)\n        results.append(result)\n    \n    end = time.time()\n    print(f\"Synchronous download time: {end - start:.2f} seconds\")\n    return results\n\n# Complete this function to download all files asynchronously\nasync def download_all_async(files):\n    start = time.time()\n    \n    # TODO: Create tasks for each file download and use asyncio.gather() to run them concurrently\n    results = []\n    for file_name, file_size in files:\n        result = await async_download_file(file_name, file_size)\n        results.append(result)\n    \n    end = time.time()\n    print(f\"Asynchronous download time: {end - start:.2f} seconds\")\n    return results\n\n# Files to download: (name, size in MB)\nfiles_to_download = [\n    (\"document.pdf\", 5),  # 0.5 seconds\n    (\"image.jpg\", 10),    # 1 second\n    (\"video.mp4\", 30)     # 3 seconds\n]\n\n# Run the synchronous download\nsync_results = download_all_sync(files_to_download)\n\n# TODO: Run the asynchronous download\n# Uncomment and complete this line:\n# async_results = await ...\n\n# Compare results\nprint(\"\\nSync download complete!\")\n# Uncomment this line:\n# print(\"Async download complete!\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### SOLUTION\n\n# Here's the solution for the practice exercise\n# It's hidden below - try to solve it yourself first!\n\n#\n#\n#\n#\n#\n# Scroll down to see the solution\n#\n#\n#\n#\n#\n#\n\nimport time\nimport asyncio\n\n# This is the correct asynchronous implementation\nasync def async_download_file_solution(file_name, file_size):\n    print(f\"Started downloading {file_name} ({file_size}MB)...\")\n    await asyncio.sleep(file_size / 10)  # Non-blocking sleep\n    print(f\"Finished downloading {file_name}\")\n    return f\"{file_name} - {file_size}MB\"\n\n# This is the correct asynchronous implementation for downloading all files\nasync def download_all_async_solution(files):\n    start = time.time()\n    \n    # Create tasks for each file download\n    tasks = [async_download_file_solution(file_name, file_size) \n             for file_name, file_size in files]\n    \n    # Run all tasks concurrently and wait for all to complete\n    results = await asyncio.gather(*tasks)\n    \n    end = time.time()\n    print(f\"Asynchronous download time: {end - start:.2f} seconds\")\n    return results\n\n# Run the asynchronous download with the solution\nasync def run_solution():\n    files_to_download = [\n        (\"document.pdf\", 5),  # 0.5 seconds\n        (\"image.jpg\", 10),    # 1 second\n        (\"video.mp4\", 30)     # 3 seconds\n    ]\n    print(\"\\nRunning the solution:\")\n    async_results = await download_all_async_solution(files_to_download)\n    print(\"Async download complete!\")\n    \n    # Expected output: The async version should take around 3 seconds (time of the largest file)\n    # rather than 4.5 seconds (sum of all download times) for the sync version\n\n# Uncomment to see the solution in action\n# await run_solution()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Asyncio\n",
    "\n",
    "Asyncio is particularly useful for:\n",
    "- I/O-bound operations (network requests, file operations)\n",
    "- Handling many concurrent connections (web servers, chat applications)\n",
    "- Operations that involve waiting (APIs with rate limits, scheduled tasks)\n",
    "\n",
    "It's less suitable for:\n",
    "- CPU-bound tasks (use multiprocessing instead)\n",
    "- Simple sequential operations with no waiting\n",
    "- Small scripts with minimal I/O operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Asyncio Basics\n",
    "\n",
    "### Coroutines and the `async`/`await` Syntax\n",
    "\n",
    "A coroutine is a specialized version of a Python generator function that can suspend and resume execution. They're created using the `async def` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a coroutine\n",
    "async def my_coroutine():\n",
    "    print(\"Coroutine started\")\n",
    "    await asyncio.sleep(1)  # Give up control and allow other coroutines to run\n",
    "    print(\"Coroutine resumed after 1 second\")\n",
    "    return \"Coroutine completed\"\n",
    "\n",
    "# This won't execute the coroutine, it just creates a coroutine object\n",
    "coro = my_coroutine()\n",
    "print(f\"Type of my_coroutine(): {type(coro)}\")\n",
    "\n",
    "# To actually run a coroutine, you need to schedule it on the event loop\n",
    "result = await my_coroutine()\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Practice!\n\nTime to practice creating and running multiple coroutines! In this exercise, you'll create a simple asynchronous countdown system.\n\nYour tasks:\n1. Complete the `countdown` coroutine to print a countdown from a given number to 1\n2. Complete the `run_countdowns` function to create and run multiple countdowns concurrently\n3. Compare the behavior with different waiting strategies",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "async def countdown(name, start_value):\n    \"\"\"\n    Coroutine that counts down from start_value to 1\n    - name: A name for this countdown to identify it in output\n    - start_value: Number to start counting down from\n    \"\"\"\n    # TODO: Implement a countdown that:\n    # 1. Prints the current count\n    # 2. Waits for 0.5 seconds between counts using asyncio.sleep()\n    # 3. Returns the total time taken when done\n    pass\n\nasync def run_countdowns():\n    \"\"\"Run multiple countdowns concurrently\"\"\"\n    print(\"Starting countdowns...\")\n    \n    # TODO: Create three countdowns with different starting values:\n    # - \"Countdown A\" starting from 5\n    # - \"Countdown B\" starting from 3\n    # - \"Countdown C\" starting from 7\n    \n    # TODO: Try both methods of running coroutines:\n    # 1. Using asyncio.gather()\n    # 2. Using asyncio.create_task() and awaiting separately\n    \n    print(\"All countdowns complete!\")\n\n# Run the exercise\n# Uncomment this line to execute:\n# await run_countdowns()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### SOLUTION\n\n# Here's the solution for the practice exercise\n# It's hidden below - try to solve it yourself first!\n\n#\n#\n#\n#\n#\n# Scroll down to see the solution\n#\n#\n#\n#\n#\n#\n\nimport time\n\nasync def countdown_solution(name, start_value):\n    \"\"\"\n    Coroutine that counts down from start_value to 1\n    - name: A name for this countdown to identify it in output\n    - start_value: Number to start counting down from\n    \"\"\"\n    start_time = time.time()\n    \n    for i in range(start_value, 0, -1):\n        print(f\"{name}: {i}\")\n        await asyncio.sleep(0.5)  # Non-blocking wait\n    \n    elapsed = time.time() - start_time\n    print(f\"{name} complete in {elapsed:.2f} seconds\")\n    return name, elapsed\n\nasync def run_countdowns_solution():\n    \"\"\"Run multiple countdowns concurrently\"\"\"\n    print(\"Starting countdowns...\")\n    \n    print(\"\\nMethod 1: Using asyncio.gather()\")\n    # Using asyncio.gather()\n    results = await asyncio.gather(\n        countdown_solution(\"Countdown A\", 5),\n        countdown_solution(\"Countdown B\", 3),\n        countdown_solution(\"Countdown C\", 7)\n    )\n    \n    for name, elapsed in results:\n        print(f\"Result: {name} took {elapsed:.2f} seconds\")\n    \n    print(\"\\nMethod 2: Using asyncio.create_task()\")\n    # Using create_task and awaiting individually\n    task_a = asyncio.create_task(countdown_solution(\"Countdown A\", 5))\n    task_b = asyncio.create_task(countdown_solution(\"Countdown B\", 3))\n    task_c = asyncio.create_task(countdown_solution(\"Countdown C\", 7))\n    \n    # Wait for all tasks to complete and get their results\n    result_a = await task_a\n    print(f\"Task completed: {result_a[0]}\")\n    \n    result_b = await task_b\n    print(f\"Task completed: {result_b[0]}\")\n    \n    result_c = await task_c\n    print(f\"Task completed: {result_c[0]}\")\n    \n    print(\"All countdowns complete!\")\n\n# Uncomment to see the solution in action\n# await run_countdowns_solution()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Event Loop\n",
    "\n",
    "The event loop is the core of every asyncio application. It's responsible for:\n",
    "- Scheduling and running asyncio tasks\n",
    "- Handling I/O events\n",
    "- Running subprocesses\n",
    "- Managing timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# In Jupyter notebooks, the event loop is already running (in IPython)\n",
    "# In regular Python scripts, you would manually run the loop like this:\n",
    "'''\n",
    "# For Python 3.7+\n",
    "asyncio.run(my_coroutine())  # Creates a new event loop and runs the coroutine\n",
    "\n",
    "# For older Python versions\n",
    "loop = asyncio.get_event_loop()\n",
    "result = loop.run_until_complete(my_coroutine())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Multiple Coroutines\n",
    "\n",
    "There are several ways to run multiple coroutines:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Practice!\n\nLet's practice working with Futures! In this exercise, you'll implement a simple task management system that uses Futures to represent pending tasks.\n\nYour tasks:\n1. Complete the `execute_task` function that takes a Future and sets its result after a delay\n2. Complete the `monitor_task` function that reports on a Future's status until it's done\n3. Complete the `task_manager` function to create and monitor multiple tasks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import random\n\nasync def execute_task(future, task_name, delay):\n    \"\"\"\n    Simulates task execution and sets the future result when done\n    - future: The Future object to complete\n    - task_name: Name of the task\n    - delay: Time in seconds that the task will take to complete\n    \"\"\"\n    # TODO: \n    # 1. Print message that the task has started\n    # 2. Pause execution for 'delay' seconds\n    # 3. Set the future's result with a message like \"Task {task_name} completed in {delay} seconds\"\n    pass\n\nasync def monitor_task(future, task_name):\n    \"\"\"\n    Monitors a future until it's done\n    - future: The Future object to monitor\n    - task_name: Name of the task\n    \"\"\"\n    # TODO:\n    # 1. Check the future's status (done or not) every 0.5 seconds\n    # 2. Print updates about the task's status\n    # 3. When the future is done, print its result and return\n    pass\n\nasync def task_manager():\n    \"\"\"Creates and manages multiple concurrent tasks using Futures\"\"\"\n    print(\"Starting task manager...\")\n    \n    # TODO: \n    # 1. Create three Future objects\n    # 2. Start the execute_task coroutine for each Future with random delays between 1-5 seconds\n    # 3. Start the monitor_task coroutine for each Future\n    # 4. Wait for all monitoring to complete\n    # 5. Print a message that all tasks are complete\n    \n    print(\"Task manager completed!\")\n\n# Uncomment to run the task manager\n# await task_manager()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### SOLUTION\n\n# Here's the solution for the practice exercise\n# It's hidden below - try to solve it yourself first!\n\n#\n#\n#\n#\n#\n# Scroll down to see the solution\n#\n#\n#\n#\n#\n#\n\nimport random\n\nasync def execute_task_solution(future, task_name, delay):\n    \"\"\"\n    Simulates task execution and sets the future result when done\n    - future: The Future object to complete\n    - task_name: Name of the task\n    - delay: Time in seconds that the task will take to complete\n    \"\"\"\n    print(f\"[Executor] {task_name} started, will take {delay:.1f} seconds\")\n    await asyncio.sleep(delay)  # Simulate the task running\n    result = f\"Task {task_name} completed in {delay:.1f} seconds\"\n    future.set_result(result)  # Set the future's result\n    print(f\"[Executor] {task_name} completed\")\n\nasync def monitor_task_solution(future, task_name):\n    \"\"\"\n    Monitors a future until it's done\n    - future: The Future object to monitor\n    - task_name: Name of the task\n    \"\"\"\n    count = 0\n    while not future.done():\n        count += 1\n        print(f\"[Monitor] {task_name}: Still running... (check {count})\")\n        await asyncio.sleep(0.5)  # Check status every 0.5 seconds\n    \n    # Once future is done, get the result\n    result = future.result()\n    print(f\"[Monitor] {task_name}: COMPLETED with result: {result}\")\n    return result\n\nasync def task_manager_solution():\n    \"\"\"Creates and manages multiple concurrent tasks using Futures\"\"\"\n    print(\"Starting task manager...\")\n    \n    # Create futures\n    future1 = asyncio.Future()\n    future2 = asyncio.Future()\n    future3 = asyncio.Future()\n    \n    # Create random delays for each task\n    delay1 = random.uniform(1, 3)\n    delay2 = random.uniform(1, 3)\n    delay3 = random.uniform(1, 3)\n    \n    # Start execution tasks (these will set future results when done)\n    asyncio.create_task(execute_task_solution(future1, \"Database Backup\", delay1))\n    asyncio.create_task(execute_task_solution(future2, \"File Indexing\", delay2))\n    asyncio.create_task(execute_task_solution(future3, \"Image Processing\", delay3))\n    \n    # Start monitoring tasks and wait for all futures to complete\n    monitor_tasks = [\n        monitor_task_solution(future1, \"Database Backup\"),\n        monitor_task_solution(future2, \"File Indexing\"),\n        monitor_task_solution(future3, \"Image Processing\")\n    ]\n    \n    # Wait for all monitors to report completion\n    results = await asyncio.gather(*monitor_tasks)\n    \n    print(\"\\nAll tasks completed with results:\")\n    for i, result in enumerate(results, 1):\n        print(f\"  Task {i}: {result}\")\n    \n    print(\"Task manager completed!\")\n\n# Uncomment to run the solution\n# await task_manager_solution()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def task1():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Task 1 completed\")\n",
    "    return \"Result 1\"\n",
    "\n",
    "async def task2():\n",
    "    await asyncio.sleep(0.5)\n",
    "    print(\"Task 2 completed\")\n",
    "    return \"Result 2\"\n",
    "\n",
    "# Method 1: Using asyncio.gather()\n",
    "print(\"Running tasks with asyncio.gather()\")\n",
    "results = await asyncio.gather(task1(), task2())\n",
    "print(f\"Results: {results}\")\n",
    "\n",
    "# Method 2: Creating and awaiting Tasks\n",
    "print(\"\\nRunning tasks with asyncio.create_task()\")\n",
    "t1 = asyncio.create_task(task1())\n",
    "t2 = asyncio.create_task(task2())\n",
    "await t1\n",
    "await t2\n",
    "print(f\"Results: {t1.result()}, {t2.result()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Practice!\n\nLet's practice working with asynchronous context managers! In this exercise, you'll create a simple resource pool that manages connections to various services.\n\nYour tasks:\n1. Complete the `AsyncResource` class implementation with proper `__aenter__` and `__aexit__` methods\n2. Create a decorator-based context manager using `@asynccontextmanager`\n3. Use both approaches to manage resources in an application scenario",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from contextlib import asynccontextmanager\n\nclass DatabaseConnection:\n    \"\"\"A mock database connection class\"\"\"\n    \n    def __init__(self, db_name):\n        self.db_name = db_name\n        self.is_connected = False\n        \n    async def connect(self):\n        print(f\"Connecting to database {self.db_name}...\")\n        await asyncio.sleep(1)  # Simulate connection time\n        self.is_connected = True\n        print(f\"Connected to {self.db_name}\")\n        \n    async def disconnect(self):\n        if self.is_connected:\n            print(f\"Disconnecting from {self.db_name}...\")\n            await asyncio.sleep(0.5)  # Simulate disconnect time\n            self.is_connected = False\n            print(f\"Disconnected from {self.db_name}\")\n            \n    async def execute_query(self, query):\n        if not self.is_connected:\n            raise RuntimeError(\"Not connected to database\")\n        print(f\"Executing query on {self.db_name}: {query}\")\n        await asyncio.sleep(0.5)  # Simulate query execution\n        return f\"Results from {query} on {self.db_name}\"\n\n\nclass AsyncDatabaseManager:\n    \"\"\"\n    Async context manager for database connections\n    \"\"\"\n    def __init__(self, db_name):\n        self.connection = DatabaseConnection(db_name)\n    \n    # TODO: Implement __aenter__ and __aexit__ methods\n    async def __aenter__(self):\n        # Your code here\n        pass\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        # Your code here\n        pass\n\n\n# TODO: Create a decorator-based context manager for the same purpose\n@asynccontextmanager\nasync def database_connection(db_name):\n    # Your code here\n    pass\n\n\nasync def run_database_operations():\n    \"\"\"Run database operations using both context manager approaches\"\"\"\n    # TODO: \n    # 1. Use the AsyncDatabaseManager class to connect to a database\n    # 2. Execute a query within the context\n    # 3. Verify that the connection is properly closed after exiting the context\n    \n    # TODO:\n    # 4. Use the database_connection function to connect to another database\n    # 5. Execute a different query within this context\n    # 6. Also verify proper connection cleanup\n    \n    # TODO: \n    # 7. Demonstrate error handling by raising an exception within one of the contexts\n    \n    pass\n\n# Uncomment to run the exercise\n# await run_database_operations()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### SOLUTION\n\n# Here's the solution for the practice exercise\n# It's hidden below - try to solve it yourself first!\n\n#\n#\n#\n#\n#\n# Scroll down to see the solution\n#\n#\n#\n#\n#\n#\n\nfrom contextlib import asynccontextmanager\n\nclass AsyncDatabaseManager_Solution:\n    \"\"\"\n    Async context manager for database connections\n    \"\"\"\n    def __init__(self, db_name):\n        self.connection = DatabaseConnection(db_name)\n    \n    async def __aenter__(self):\n        # Connect to the database when entering the context\n        await self.connection.connect()\n        return self.connection  # Return the connection for use inside the context\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        # Disconnect when exiting the context, even if an error occurred\n        await self.connection.disconnect()\n        # By returning False, we ensure that any exceptions are propagated\n        return False\n\n\n@asynccontextmanager\nasync def database_connection_solution(db_name):\n    # Create and connect to database\n    connection = DatabaseConnection(db_name)\n    try:\n        await connection.connect()\n        yield connection  # Provide the connection to the context\n    finally:\n        # Always disconnect, even if there was an error\n        await connection.disconnect()\n\n\nasync def run_database_operations_solution():\n    \"\"\"Run database operations using both context manager approaches\"\"\"\n    print(\"\\n=== Using class-based async context manager ===\")\n    try:\n        # Use the class-based context manager\n        async with AsyncDatabaseManager_Solution(\"ProductDB\") as db:\n            result = await db.execute_query(\"SELECT * FROM products\")\n            print(f\"Got result: {result}\")\n    except Exception as e:\n        print(f\"Error using class-based manager: {e}\")\n    \n    print(\"\\n=== Using decorator-based async context manager ===\")\n    try:\n        # Use the decorator-based context manager\n        async with database_connection_solution(\"UserDB\") as db:\n            result = await db.execute_query(\"SELECT * FROM users\")\n            print(f\"Got result: {result}\")\n    except Exception as e:\n        print(f\"Error using decorator-based manager: {e}\")\n    \n    print(\"\\n=== Demonstrating error handling ===\")\n    try:\n        # Demonstrate error handling\n        async with AsyncDatabaseManager_Solution(\"LogDB\") as db:\n            print(\"About to raise an exception...\")\n            raise ValueError(\"Something went wrong!\")\n            # This line never executes\n            result = await db.execute_query(\"SELECT * FROM logs\")\n    except ValueError as e:\n        print(f\"Successfully caught exception: {e}\")\n    \n    print(\"\\nAll database operations completed\")\n\n# Uncomment to run the solution\n# await run_database_operations_solution()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with Tasks and Futures\n",
    "\n",
    "### Tasks\n",
    "\n",
    "A Task is a wrapper around a coroutine that schedules it to run on the event loop. Tasks allow you to run coroutines concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def long_running_task(name, duration):\n",
    "    print(f\"{name} started\")\n",
    "    await asyncio.sleep(duration)\n",
    "    print(f\"{name} completed after {duration}s\")\n",
    "    return f\"{name} result\"\n",
    "\n",
    "async def manage_tasks():\n",
    "    # Create tasks\n",
    "    task_a = asyncio.create_task(long_running_task(\"Task A\", 3))\n",
    "    task_b = asyncio.create_task(long_running_task(\"Task B\", 2))\n",
    "    task_c = asyncio.create_task(long_running_task(\"Task C\", 1))\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    await asyncio.gather(task_a, task_b, task_c)\n",
    "    \n",
    "    print(f\"Task A result: {task_a.result()}\")\n",
    "    print(f\"Task B result: {task_b.result()}\")\n",
    "    print(f\"Task C result: {task_c.result()}\")\n",
    "\n",
    "await manage_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Cancellation\n",
    "\n",
    "You can cancel running tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Practice!\n\nLet's practice using asyncio queues to build a producer-consumer system. In this exercise, you'll implement a simple task processing system where:\n\n1. Multiple producers generate tasks and put them into a queue\n2. Multiple consumers take tasks from the queue and process them\n3. The system should handle backpressure (when producers are faster than consumers)\n\nYour tasks:\n1. Complete the producer function to generate tasks and add them to the queue\n2. Complete the consumer function to process tasks from the queue\n3. Complete the main function to set up and run the system",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import random\n\nasync def task_producer(queue, producer_id, num_tasks):\n    \"\"\"\n    Produces tasks and puts them into the queue\n    - queue: The asyncio.Queue to add tasks to\n    - producer_id: ID to identify this producer\n    - num_tasks: Number of tasks to produce\n    \"\"\"\n    # TODO:\n    # 1. Create a loop to generate 'num_tasks' tasks\n    # 2. For each task, create a task description like f\"Task {producer_id}-{task_num}\"\n    # 3. Put the task into the queue using queue.put()\n    # 4. Add a small random delay between producing tasks (0.1-0.5 seconds)\n    # 5. Print messages when starting/finishing production\n    pass\n    \nasync def task_consumer(queue, consumer_id, processing_time):\n    \"\"\"\n    Consumes tasks from the queue and processes them\n    - queue: The asyncio.Queue to get tasks from\n    - consumer_id: ID to identify this consumer\n    - processing_time: Time in seconds each task takes to process\n    \"\"\"\n    # TODO:\n    # 1. Create an infinite loop to continuously check for tasks\n    # 2. Get tasks from the queue using queue.get()\n    # 3. Process each task by waiting for 'processing_time' seconds\n    # 4. Print messages when starting/finishing processing\n    # 5. Call queue.task_done() after processing each task\n    # 6. Add exception handling in case of errors\n    pass\n\nasync def producer_consumer_demo():\n    \"\"\"\n    Sets up and runs the producer-consumer system\n    \"\"\"\n    # TODO:\n    # 1. Create a queue with a maximum size of 5 tasks\n    # 2. Create 2 producers that generate 5 tasks each\n    # 3. Create 3 consumers with different processing times\n    # 4. Start all producers and consumers\n    # 5. Wait for all producers to finish\n    # 6. Wait for the queue to be empty (all tasks processed)\n    # 7. Cancel the consumer tasks (which are in infinite loops)\n    # 8. Print a final summary message\n    pass\n\n# Uncomment to run the demo\n# await producer_consumer_demo()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### SOLUTION\n\n# Here's the solution for the practice exercise\n# It's hidden below - try to solve it yourself first!\n\n#\n#\n#\n#\n#\n# Scroll down to see the solution\n#\n#\n#\n#\n#\n#\n\nimport random\n\nasync def task_producer_solution(queue, producer_id, num_tasks):\n    \"\"\"\n    Produces tasks and puts them into the queue\n    - queue: The asyncio.Queue to add tasks to\n    - producer_id: ID to identify this producer\n    - num_tasks: Number of tasks to produce\n    \"\"\"\n    print(f\"Producer {producer_id}: Starting, will produce {num_tasks} tasks\")\n    \n    for i in range(1, num_tasks + 1):\n        # Create a task with producer ID and task number\n        task = f\"Task {producer_id}-{i}\"\n        \n        # Put the task in the queue, this will wait if the queue is full\n        print(f\"Producer {producer_id}: Adding {task} to queue\")\n        await queue.put(task)\n        \n        # Random delay between tasks\n        delay = random.uniform(0.1, 0.5)\n        await asyncio.sleep(delay)\n    \n    print(f\"Producer {producer_id}: Finished producing all {num_tasks} tasks\")\n    \nasync def task_consumer_solution(queue, consumer_id, processing_time):\n    \"\"\"\n    Consumes tasks from the queue and processes them\n    - queue: The asyncio.Queue to get tasks from\n    - consumer_id: ID to identify this consumer\n    - processing_time: Time in seconds each task takes to process\n    \"\"\"\n    print(f\"Consumer {consumer_id}: Starting (processing time: {processing_time}s per task)\")\n    \n    # Track processed tasks for reporting\n    tasks_processed = 0\n    \n    try:\n        while True:  # Infinite loop to keep processing tasks\n            # Get a task from the queue\n            task = await queue.get()\n            tasks_processed += 1\n            \n            # Process the task\n            print(f\"Consumer {consumer_id}: Processing {task}\")\n            await asyncio.sleep(processing_time)  # Simulate processing time\n            print(f\"Consumer {consumer_id}: Completed {task}\")\n            \n            # Signal that the task is done\n            queue.task_done()\n    except asyncio.CancelledError:\n        # Handle cancellation gracefully\n        print(f\"Consumer {consumer_id}: Shutting down after processing {tasks_processed} tasks\")\n        raise\n    except Exception as e:\n        print(f\"Consumer {consumer_id}: Error processing task: {e}\")\n        queue.task_done()  # Don't forget to mark the task as done even on errors\n\nasync def producer_consumer_demo_solution():\n    \"\"\"\n    Sets up and runs the producer-consumer system\n    \"\"\"\n    # Create a queue with maximum size 5 to demonstrate backpressure\n    queue = asyncio.Queue(maxsize=5)\n    \n    # Create and start producers\n    producer_tasks = [\n        asyncio.create_task(task_producer_solution(queue, 1, 5)),\n        asyncio.create_task(task_producer_solution(queue, 2, 5))\n    ]\n    \n    # Create and start consumers with different processing speeds\n    consumer_tasks = [\n        asyncio.create_task(task_consumer_solution(queue, 1, 0.7)),\n        asyncio.create_task(task_consumer_solution(queue, 2, 1.0)),\n        asyncio.create_task(task_consumer_solution(queue, 3, 0.5))\n    ]\n    \n    # Wait for all producers to finish\n    print(\"Waiting for producers to finish...\")\n    await asyncio.gather(*producer_tasks)\n    print(\"All producers have finished!\")\n    \n    # Wait for the queue to be empty (all tasks processed)\n    print(\"Waiting for all tasks to be processed...\")\n    await queue.join()\n    \n    # All tasks are done, cancel the consumer tasks\n    print(\"All tasks processed, cancelling consumers...\")\n    for consumer in consumer_tasks:\n        consumer.cancel()\n    \n    # Wait for consumers to finish cancellation\n    await asyncio.gather(*consumer_tasks, return_exceptions=True)\n    \n    print(\"\\nProducer-Consumer demo completed\")\n    print(f\"Total tasks produced: 10\")\n    print(f\"Queue size at end: {queue.qsize()}\")\n    print(f\"All tasks successfully processed!\")\n\n# Uncomment to run the solution\n# await producer_consumer_demo_solution()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cancellable_task():\n",
    "    try:\n",
    "        print(\"Task started\")\n",
    "        while True:  # Infinite loop\n",
    "            print(\"Working...\")\n",
    "            await asyncio.sleep(0.5)\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Task was cancelled!\")\n",
    "        raise  # Re-raise to properly handle cancellation\n",
    "\n",
    "async def cancel_after_delay(task, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    task.cancel()\n",
    "    print(f\"Cancellation request sent after {delay}s\")\n",
    "\n",
    "async def demo_cancellation():\n",
    "    task = asyncio.create_task(cancellable_task())\n",
    "    # Schedule the task to be cancelled after 2 seconds\n",
    "    asyncio.create_task(cancel_after_delay(task, 2))\n",
    "    \n",
    "    try:\n",
    "        await task\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Main function caught the cancellation\")\n",
    "\n",
    "await demo_cancellation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Futures\n",
    "\n",
    "A Future is a low-level awaitable object that represents an eventual result of an asynchronous operation. Tasks are a subclass of Future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_future_result(future, value, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    future.set_result(value)\n",
    "\n",
    "async def future_demo():\n",
    "    # Create a future\n",
    "    future = asyncio.Future()\n",
    "    \n",
    "    # Schedule a coroutine to set the future's result\n",
    "    asyncio.create_task(set_future_result(future, \"Future result\", 2))\n",
    "    \n",
    "    # Wait for the future to have a result\n",
    "    print(\"Waiting for future result...\")\n",
    "    result = await future\n",
    "    print(f\"Got result: {result}\")\n",
    "\n",
    "await future_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Context Managers\n",
    "\n",
    "Asyncio provides the asynchronous counterpart to Python's context managers. This allows resources to be properly managed asynchronously, especially when acquisition or release operations are I/O-bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class with __aenter__ and __aexit__ methods\n",
    "class AsyncResource:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    async def __aenter__(self):\n",
    "        print(f\"Acquiring {self.name} asynchronously...\")\n",
    "        await asyncio.sleep(1)  # Simulate async resource acquisition\n",
    "        print(f\"{self.name} acquired\")\n",
    "        return self\n",
    "        \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        print(f\"Releasing {self.name} asynchronously...\")\n",
    "        await asyncio.sleep(0.5)  # Simulate async resource release\n",
    "        print(f\"{self.name} released\")\n",
    "        # Returning False means exceptions propagate, True would suppress them\n",
    "        return False\n",
    "        \n",
    "    async def use_resource(self):\n",
    "        print(f\"Using {self.name}\")\n",
    "        await asyncio.sleep(0.5)\n",
    "        return f\"{self.name} result\"\n",
    "\n",
    "# Using an async context manager with \"async with\"\n",
    "async def async_context_demo():\n",
    "    # Method 1: Using async with\n",
    "    print(\"Using async with:\")\n",
    "    async with AsyncResource(\"Database Connection\") as resource:\n",
    "        result = await resource.use_resource()\n",
    "        print(f\"Got result: {result}\")\n",
    "    \n",
    "    # Method 2: Using try/finally and manual enter/exit\n",
    "    print(\"\\nUsing manual enter/exit:\")\n",
    "    resource = AsyncResource(\"File Handle\")\n",
    "    try:\n",
    "        await resource.__aenter__()\n",
    "        result = await resource.use_resource()\n",
    "        print(f\"Got result: {result}\")\n",
    "    finally:\n",
    "        await resource.__aexit__(None, None, None)\n",
    "        \n",
    "    # Method 3: Error handling demonstration\n",
    "    print(\"\\nHandling exceptions in async context managers:\")\n",
    "    try:\n",
    "        async with AsyncResource(\"Network Connection\") as resource:\n",
    "            print(\"About to raise an exception...\")\n",
    "            raise ValueError(\"Something went wrong!\")\n",
    "            # This line never executes\n",
    "            result = await resource.use_resource()\n",
    "    except ValueError as e:\n",
    "        print(f\"Caught exception: {e}\")\n",
    "\n",
    "await async_context_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `__aenter__` and `__aexit__` allows you to create asynchronous context managers that can:\n",
    "\n",
    "1. Asynchronously acquire and release resources\n",
    "2. Properly handle exceptions that occur within the context\n",
    "3. Ensure resources are cleaned up even when errors occur\n",
    "\n",
    "Common use cases include:\n",
    "- Database connections requiring async setup/teardown\n",
    "- Network resources with async initialization\n",
    "- File I/O operations with aiofiles\n",
    "- Connection pools that need to be acquired/released asynchronously\n",
    "\n",
    "The `asynccontextmanager` decorator from `contextlib` provides an alternative way to create async context managers without implementing a full class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "\n",
    "@asynccontextmanager\n",
    "async def managed_resource(name):\n",
    "    print(f\"Acquiring {name}...\")\n",
    "    await asyncio.sleep(1)  # Simulate async acquisition\n",
    "    try:\n",
    "        yield name  # Provide the resource\n",
    "    finally:\n",
    "        print(f\"Releasing {name}...\")\n",
    "        await asyncio.sleep(0.5)  # Simulate async release\n",
    "        print(f\"{name} released\")\n",
    "\n",
    "async def contextmanager_demo():\n",
    "    async with managed_resource(\"API Connection\") as resource:\n",
    "        print(f\"Using {resource}\")\n",
    "        await asyncio.sleep(0.5)\n",
    "        print(\"Operation complete\")\n",
    "\n",
    "await contextmanager_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for Multiple Tasks\n",
    "\n",
    "You can wait for multiple tasks with different strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def wait_demo():\n",
    "    tasks = [\n",
    "        asyncio.create_task(long_running_task(\"Task X\", 3)),\n",
    "        asyncio.create_task(long_running_task(\"Task Y\", 1)),\n",
    "        asyncio.create_task(long_running_task(\"Task Z\", 2))\n",
    "    ]\n",
    "    \n",
    "    # Wait for the first task to complete\n",
    "    print(\"\\nWaiting for the first task to complete...\")\n",
    "    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "    \n",
    "    print(f\"\\n{len(done)} task(s) completed:\")\n",
    "    for task in done:\n",
    "        print(f\"  - {task.result()}\")\n",
    "        \n",
    "    print(f\"\\n{len(pending)} task(s) still pending\")\n",
    "    \n",
    "    # Wait for the remaining tasks\n",
    "    print(\"\\nWaiting for remaining tasks...\")\n",
    "    done, pending = await asyncio.wait(pending)\n",
    "    \n",
    "    print(f\"\\nAll tasks completed. Results:\")\n",
    "    for task in tasks:\n",
    "        print(f\"  - {task.result()}\")\n",
    "\n",
    "await wait_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Practice!\n\nLet's practice proper error handling in asyncio applications. In this exercise, you'll build a system to process a batch of URLs, handling different types of errors that might occur.\n\nYour tasks:\n1. Complete the `fetch_url` function to handle connection errors and timeouts gracefully\n2. Complete the `process_batch` function to process multiple URLs in parallel with proper error handling\n3. Implement three approaches for handling errors in asyncio tasks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class NotFoundException(Exception):\n    \"\"\"Raised when a resource is not found\"\"\"\n    pass\n\nclass TimeoutException(Exception):\n    \"\"\"Raised when an operation times out\"\"\"\n    pass\n\nclass ServerException(Exception):\n    \"\"\"Raised when a server error occurs\"\"\"\n    pass\n\nasync def simulate_request(url):\n    \"\"\"\n    Simulates an HTTP request that might succeed, fail, or timeout\n    This is a helper function for the exercise - you don't need to modify it\n    \"\"\"\n    # Delay to simulate network latency\n    await asyncio.sleep(random.uniform(0.1, 0.5))\n    \n    # Simulate different response scenarios\n    if \"notfound\" in url:\n        raise NotFoundException(f\"Resource not found: {url}\")\n    elif \"timeout\" in url:\n        raise TimeoutException(f\"Request timed out: {url}\")\n    elif \"error\" in url:\n        raise ServerException(f\"Server error for: {url}\")\n    elif \"slow\" in url:\n        # This is a slow but ultimately successful request\n        await asyncio.sleep(2)\n        return f\"Slow response from {url}\"\n    else:\n        return f\"Success! Data from {url}\"\n\nasync def fetch_url(url, timeout=1.0):\n    \"\"\"\n    Fetches a URL with proper error handling and timeout\n    - url: The URL to fetch\n    - timeout: Maximum time to wait before timing out\n    \n    Should return a tuple of (url, status, result)\n    where status is 'success', 'not_found', 'timeout', or 'error'\n    and result contains either the data or the error message\n    \"\"\"\n    # TODO:\n    # 1. Implement proper exception handling for different error types\n    # 2. Add a timeout using asyncio.wait_for\n    # 3. Return appropriate status and result values depending on the outcome\n    pass\n\nasync def process_batch_method1():\n    \"\"\"\n    Process multiple URLs using individual try/except blocks\n    \"\"\"\n    print(\"Method 1: Individual try/except around each task\")\n    \n    urls = [\n        \"https://example.com/api/data\",\n        \"https://example.com/api/notfound\",\n        \"https://example.com/api/timeout\",\n        \"https://example.com/api/error\",\n        \"https://example.com/api/slow\"\n    ]\n    \n    # TODO:\n    # 1. Process each URL individually with its own try/except\n    # 2. Print the results, showing success or the specific error for each URL\n    pass\n\nasync def process_batch_method2():\n    \"\"\"\n    Process multiple URLs using gather with return_exceptions=True\n    \"\"\"\n    print(\"\\nMethod 2: Using gather with return_exceptions=True\")\n    \n    urls = [\n        \"https://example.com/api/data\",\n        \"https://example.com/api/notfound\",\n        \"https://example.com/api/timeout\",\n        \"https://example.com/api/error\",\n        \"https://example.com/api/slow\"\n    ]\n    \n    # TODO:\n    # 1. Create tasks for each URL\n    # 2. Use asyncio.gather with return_exceptions=True\n    # 3. Process the results, distinguishing between successful results and exceptions\n    pass\n\nasync def process_batch_method3():\n    \"\"\"\n    Process multiple URLs using tasks with callbacks\n    \"\"\"\n    print(\"\\nMethod 3: Using tasks with callbacks\")\n    \n    urls = [\n        \"https://example.com/api/data\",\n        \"https://example.com/api/notfound\",\n        \"https://example.com/api/timeout\",\n        \"https://example.com/api/error\",\n        \"https://example.com/api/slow\"\n    ]\n    \n    # TODO:\n    # 1. Create a callback function to handle task completion and exceptions\n    # 2. Create and start tasks for each URL\n    # 3. Add the callback to each task\n    # 4. Wait for all tasks to complete\n    pass\n\nasync def error_handling_exercise():\n    \"\"\"Run all three methods of error handling\"\"\"\n    await process_batch_method1()\n    await process_batch_method2()\n    await process_batch_method3()\n    print(\"\\nAll error handling methods demonstrated!\")\n\n# Uncomment to run the exercise\n# await error_handling_exercise()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### SOLUTION\n\n# Here's the solution for the practice exercise\n# It's hidden below - try to solve it yourself first!\n\n#\n#\n#\n#\n#\n# Scroll down to see the solution\n#\n#\n#\n#\n#\n#\n\nasync def fetch_url_solution(url, timeout=1.0):\n    \"\"\"\n    Fetches a URL with proper error handling and timeout\n    \"\"\"\n    try:\n        # Try to fetch the URL with a timeout\n        try:\n            result = await asyncio.wait_for(simulate_request(url), timeout)\n            return url, 'success', result\n        except asyncio.TimeoutError:\n            return url, 'timeout', f\"Request timed out after {timeout} seconds\"\n            \n    except NotFoundException as e:\n        return url, 'not_found', str(e)\n    except TimeoutException as e:\n        return url, 'timeout', str(e)\n    except ServerException as e:\n        return url, 'error', str(e)\n    except Exception as e:\n        # Catch any other unexpected exceptions\n        return url, 'error', f\"Unexpected error: {str(e)}\"\n\nasync def process_batch_method1_solution():\n    \"\"\"\n    Process multiple URLs using individual try/except blocks\n    \"\"\"\n    print(\"Method 1: Individual try/except around each task\")\n    \n    urls = [\n        \"https://example.com/api/data\",\n        \"https://example.com/api/notfound\",\n        \"https://example.com/api/timeout\",\n        \"https://example.com/api/error\",\n        \"https://example.com/api/slow\"\n    ]\n    \n    results = []\n    \n    # Process each URL individually\n    for url in urls:\n        try:\n            print(f\"Processing {url}...\")\n            result = await fetch_url_solution(url)\n            print(f\"Result: {result[1]} - {result[2]}\")\n            results.append(result)\n        except Exception as e:\n            # This should never happen because fetch_url handles all exceptions\n            print(f\"Unexpected error processing {url}: {e}\")\n            results.append((url, 'error', str(e)))\n    \n    # Summary\n    print(\"\\nSummary:\")\n    for url, status, message in results:\n        print(f\"  {url}: {status}\")\n\nasync def process_batch_method2_solution():\n    \"\"\"\n    Process multiple URLs using gather with return_exceptions=True\n    \"\"\"\n    print(\"\\nMethod 2: Using gather with return_exceptions=True\")\n    \n    urls = [\n        \"https://example.com/api/data\",\n        \"https://example.com/api/notfound\",\n        \"https://example.com/api/timeout\",\n        \"https://example.com/api/error\",\n        \"https://example.com/api/slow\"\n    ]\n    \n    # Create tasks for each URL\n    tasks = [fetch_url_solution(url) for url in urls]\n    \n    # Wait for all tasks, getting either results or exceptions\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    \n    # Process and display results\n    print(\"\\nResults:\")\n    for i, result in enumerate(results):\n        if isinstance(result, Exception):\n            # This is an exception that wasn't caught in fetch_url\n            print(f\"  {urls[i]}: Error - {str(result)}\")\n        else:\n            url, status, message = result\n            print(f\"  {url}: {status} - {message}\")\n\nasync def process_batch_method3_solution():\n    \"\"\"\n    Process multiple URLs using tasks with callbacks\n    \"\"\"\n    print(\"\\nMethod 3: Using tasks with callbacks\")\n    \n    urls = [\n        \"https://example.com/api/data\",\n        \"https://example.com/api/notfound\",\n        \"https://example.com/api/timeout\",\n        \"https://example.com/api/error\",\n        \"https://example.com/api/slow\"\n    ]\n    \n    # Dictionary to track results\n    results = {}\n    \n    # Callback function to handle task completion\n    def task_done(task):\n        try:\n            url, status, message = task.result()\n            results[url] = (status, message)\n            print(f\"Callback: {url} completed with status '{status}'\")\n        except Exception as e:\n            # This happens if fetch_url itself raises an uncaught exception\n            url = task.get_name()\n            results[url] = ('error', str(e))\n            print(f\"Callback: Error in task for {url}: {e}\")\n    \n    # Create and start tasks\n    tasks = []\n    for url in urls:\n        # Create task with a name that identifies the URL\n        task = asyncio.create_task(fetch_url_solution(url), name=url)\n        # Add the callback to handle completion\n        task.add_done_callback(task_done)\n        tasks.append(task)\n    \n    # Wait for all tasks to complete\n    await asyncio.gather(*tasks, return_exceptions=True)\n    \n    # Summary\n    print(\"\\nSummary from callbacks:\")\n    for url, (status, message) in results.items():\n        print(f\"  {url}: {status}\")\n\nasync def error_handling_exercise_solution():\n    \"\"\"Run all three methods of error handling\"\"\"\n    await process_batch_method1_solution()\n    await process_batch_method2_solution()\n    await process_batch_method3_solution()\n    print(\"\\nAll error handling methods demonstrated!\")\n\n# Uncomment to run the solution\n# await error_handling_exercise_solution()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Asyncio Concepts\n",
    "\n",
    "### Timeouts\n",
    "\n",
    "You can add timeouts to operations to prevent them from running too long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def potentially_slow_operation():\n",
    "    print(\"Slow operation started\")\n",
    "    await asyncio.sleep(5)  # Simulate a slow operation\n",
    "    print(\"Slow operation finished\")\n",
    "    return \"Operation result\"\n",
    "\n",
    "async def timeout_demo():\n",
    "    try:\n",
    "        # Set a 2-second timeout for the operation\n",
    "        result = await asyncio.wait_for(potentially_slow_operation(), timeout=2)\n",
    "        print(f\"Got result: {result}\")\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Operation timed out!\")\n",
    "\n",
    "await timeout_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asyncio Queues\n",
    "\n",
    "Asyncio provides queue implementations for coordinating between producer and consumer coroutines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def producer(queue, name, items):\n",
    "    for i in range(items):\n",
    "        item = f\"{name} item {i}\"\n",
    "        await queue.put(item)\n",
    "        print(f\"{name} produced: {item}\")\n",
    "        await asyncio.sleep(0.5)\n",
    "    print(f\"{name} finished producing\")\n",
    "\n",
    "async def consumer(queue, name, items_to_process):\n",
    "    for _ in range(items_to_process):\n",
    "        item = await queue.get()\n",
    "        print(f\"{name} consumed: {item}\")\n",
    "        queue.task_done()\n",
    "        await asyncio.sleep(1)  # Simulate processing time\n",
    "    print(f\"{name} finished consuming\")\n",
    "\n",
    "async def queue_demo():\n",
    "    # Create a queue\n",
    "    queue = asyncio.Queue(maxsize=5)  # Limit queue size to 5 items\n",
    "    \n",
    "    # Create tasks for producers and consumers\n",
    "    producer_tasks = [\n",
    "        asyncio.create_task(producer(queue, \"Producer 1\", 4)),\n",
    "        asyncio.create_task(producer(queue, \"Producer 2\", 3))\n",
    "    ]\n",
    "    \n",
    "    consumer_tasks = [\n",
    "        asyncio.create_task(consumer(queue, \"Consumer 1\", 3)),\n",
    "        asyncio.create_task(consumer(queue, \"Consumer 2\", 4))\n",
    "    ]\n",
    "    \n",
    "    # Wait for all producers to finish\n",
    "    await asyncio.gather(*producer_tasks)\n",
    "    \n",
    "    # Wait for the queue to be fully processed\n",
    "    await queue.join()\n",
    "    \n",
    "    # Wait for all consumers to finish\n",
    "    await asyncio.gather(*consumer_tasks)\n",
    "    \n",
    "    print(\"Queue demo completed\")\n",
    "\n",
    "await queue_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronization Primitives\n",
    "\n",
    "Asyncio provides synchronization primitives similar to the ones in the `threading` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def worker(lock, worker_id, shared_resource):\n",
    "    print(f\"Worker {worker_id} is waiting for the lock\")\n",
    "    async with lock:  # Acquire and release the lock automatically\n",
    "        print(f\"Worker {worker_id} acquired the lock\")\n",
    "        # Simulate working with a shared resource\n",
    "        shared_resource.append(worker_id)\n",
    "        print(f\"Worker {worker_id} updated shared resource: {shared_resource}\")\n",
    "        await asyncio.sleep(1)  # Simulate some work\n",
    "    print(f\"Worker {worker_id} released the lock\")\n",
    "\n",
    "async def lock_demo():\n",
    "    # Create a lock\n",
    "    lock = asyncio.Lock()\n",
    "    shared_resource = []\n",
    "    \n",
    "    # Create and run multiple workers concurrently\n",
    "    workers = [worker(lock, i, shared_resource) for i in range(3)]\n",
    "    await asyncio.gather(*workers)\n",
    "    \n",
    "    print(f\"Final shared resource: {shared_resource}\")\n",
    "\n",
    "await lock_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Examples\n",
    "\n",
    "### Asynchronous Web Requests\n",
    "\n",
    "Let's use `aiohttp` to make concurrent web requests (install with `pip install aiohttp` if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import aiohttp\n",
    "except ImportError:\n",
    "    print(\"aiohttp is not installed. Please install it with:\")\n",
    "    print(\"pip install aiohttp\")\n",
    "    print(\"\\nFor now, we'll skip this example.\")\n",
    "else:\n",
    "    async def fetch_url(session, url):\n",
    "        print(f\"Fetching {url}\")\n",
    "        async with session.get(url) as response:\n",
    "            if response.status != 200:\n",
    "                return f\"Error: {response.status} for {url}\"\n",
    "            data = await response.text()\n",
    "            return f\"Fetched {len(data)} bytes from {url}\"\n",
    "\n",
    "    async def fetch_multiple_urls():\n",
    "        urls = [\n",
    "            \"https://example.com\",\n",
    "            \"https://python.org\",\n",
    "            \"https://docs.python.org/\"\n",
    "        ]\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [fetch_url(session, url) for url in urls]\n",
    "            results = await asyncio.gather(*tasks)\n",
    "            \n",
    "            for i, result in enumerate(results):\n",
    "                print(f\"Result {i+1}: {result}\")\n",
    "\n",
    "    # Run the example if aiohttp is installed\n",
    "    try:\n",
    "        await fetch_multiple_urls()\n",
    "    except NameError:\n",
    "        pass  # Skip if aiohttp isn't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File I/O with aiofiles\n",
    "\n",
    "Let's use `aiofiles` for asynchronous file operations (install with `pip install aiofiles` if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import aiofiles\n",
    "except ImportError:\n",
    "    print(\"aiofiles is not installed. Please install it with:\")\n",
    "    print(\"pip install aiofiles\")\n",
    "    print(\"\\nFor now, we'll skip this example.\")\n",
    "else:\n",
    "    async def write_file(filename, content):\n",
    "        print(f\"Writing to {filename}\")\n",
    "        async with aiofiles.open(filename, 'w') as file:\n",
    "            await file.write(content)\n",
    "        print(f\"Finished writing to {filename}\")\n",
    "\n",
    "    async def read_file(filename):\n",
    "        print(f\"Reading from {filename}\")\n",
    "        async with aiofiles.open(filename, 'r') as file:\n",
    "            content = await file.read()\n",
    "        print(f\"Read {len(content)} bytes from {filename}\")\n",
    "        return content\n",
    "\n",
    "    async def file_io_demo():\n",
    "        # Write files concurrently\n",
    "        write_tasks = [\n",
    "            write_file('asyncio_demo_1.txt', 'This is file 1 content\\n' * 1000),\n",
    "            write_file('asyncio_demo_2.txt', 'This is file 2 content\\n' * 1000),\n",
    "            write_file('asyncio_demo_3.txt', 'This is file 3 content\\n' * 1000)\n",
    "        ]\n",
    "        await asyncio.gather(*write_tasks)\n",
    "        \n",
    "        # Read files concurrently\n",
    "        read_tasks = [\n",
    "            read_file('asyncio_demo_1.txt'),\n",
    "            read_file('asyncio_demo_2.txt'),\n",
    "            read_file('asyncio_demo_3.txt')\n",
    "        ]\n",
    "        results = await asyncio.gather(*read_tasks)\n",
    "        \n",
    "        # Clean up demo files (optional)\n",
    "        import os\n",
    "        for i in range(1, 4):\n",
    "            os.remove(f'asyncio_demo_{i}.txt')\n",
    "            \n",
    "        print(\"File I/O demo completed\")\n",
    "\n",
    "    # Run the example if aiofiles is installed\n",
    "    try:\n",
    "        await file_io_demo()\n",
    "    except NameError:\n",
    "        pass  # Skip if aiofiles isn't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Simple Asynchronous Server\n",
    "\n",
    "Let's build a very simple echo server using asyncio streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_client(reader, writer):\n",
    "    # Get client address\n",
    "    addr = writer.get_extra_info('peername')\n",
    "    print(f\"Client connected: {addr}\")\n",
    "    \n",
    "    while True:\n",
    "        # Read data from the client\n",
    "        data = await reader.read(100)\n",
    "        message = data.decode()\n",
    "        \n",
    "        if not data:  # Client disconnected\n",
    "            break\n",
    "            \n",
    "        print(f\"Received from {addr}: {message.strip()}\")\n",
    "        \n",
    "        # Echo the message back to the client\n",
    "        response = f\"Echo: {message}\"\n",
    "        writer.write(response.encode())\n",
    "        await writer.drain()\n",
    "        \n",
    "    # Close the connection\n",
    "    print(f\"Client disconnected: {addr}\")\n",
    "    writer.close()\n",
    "    await writer.wait_closed()\n",
    "\n",
    "async def run_server():\n",
    "    server = await asyncio.start_server(\n",
    "        handle_client, '127.0.0.1', 8888)\n",
    "    \n",
    "    # Get server address\n",
    "    addr = server.sockets[0].getsockname()\n",
    "    print(f\"Server running on {addr}\")\n",
    "    \n",
    "    print(\"To test the server:\")\n",
    "    print(\"1. Open another terminal\")\n",
    "    print(\"2. Use: telnet 127.0.0.1 8888\")\n",
    "    print(\"3. Type messages and see them echoed back\")\n",
    "    print(\"4. Press Ctrl+C here to stop the server\")\n",
    "    \n",
    "    try:\n",
    "        async with server:\n",
    "            # This will keep the server running until cancelled\n",
    "            await server.serve_forever()\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Server stopped\")\n",
    "\n",
    "# Uncomment to run the server (note: this will block the notebook until cancelled)\n",
    "# await run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating a Real-world Application: Web Crawler\n",
    "\n",
    "Let's build a simple asynchronous web crawler that respects rate limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import aiohttp\n",
    "    from bs4 import BeautifulSoup\n",
    "except ImportError:\n",
    "    print(\"Required packages not installed. Please install them with:\")\n",
    "    print(\"pip install aiohttp beautifulsoup4\")\n",
    "    print(\"\\nSkipping this example.\")\n",
    "else:\n",
    "    class AsyncCrawler:\n",
    "        def __init__(self, base_url, max_urls=10, rate_limit=1):\n",
    "            self.base_url = base_url\n",
    "            self.to_visit = asyncio.Queue()\n",
    "            self.visited = set()\n",
    "            self.max_urls = max_urls\n",
    "            self.rate_limit = rate_limit  # Seconds between requests\n",
    "            self.session = None\n",
    "            self.rate_limiter = asyncio.Semaphore(1)  # Only 1 request at a time\n",
    "            \n",
    "        async def __aenter__(self):\n",
    "            self.session = aiohttp.ClientSession()\n",
    "            await self.to_visit.put(self.base_url)\n",
    "            return self\n",
    "            \n",
    "        async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "            assert self.session is not None, \"Session is not initialized\"\n",
    "            await self.session.close()\n",
    "            \n",
    "        async def fetch_url(self, url):\n",
    "            async with self.rate_limiter:\n",
    "                print(f\"Fetching: {url}\")\n",
    "                try:\n",
    "                    assert self.session is not None, \"Session must be initialized\"\n",
    "                    async with self.session.get(url) as response:\n",
    "                        if response.status != 200:\n",
    "                            print(f\"Error: {response.status} for {url}\")\n",
    "                            return None\n",
    "                            \n",
    "                        html = await response.text()\n",
    "                        print(f\"Fetched {len(html)} bytes from {url}\")\n",
    "                        # Respect rate limit\n",
    "                        await asyncio.sleep(self.rate_limit)\n",
    "                        return html\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching {url}: {e}\")\n",
    "                    return None\n",
    "                    \n",
    "        def extract_links(self, html, url):\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            links = set()\n",
    "            \n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                \n",
    "                # Handle relative URLs\n",
    "                if href.startswith('/'):\n",
    "                    href = f\"{self.base_url.rstrip('/')}{href}\"\n",
    "                    \n",
    "                # Only follow links from the same domain\n",
    "                if href.startswith(self.base_url) and href not in self.visited:\n",
    "                    links.add(href)\n",
    "                    \n",
    "            print(f\"Found {len(links)} new links on {url}\")\n",
    "            return links\n",
    "            \n",
    "        async def crawl(self):\n",
    "            while len(self.visited) < self.max_urls:\n",
    "                if self.to_visit.empty():\n",
    "                    print(\"No more URLs to visit\")\n",
    "                    break\n",
    "                    \n",
    "                url = await self.to_visit.get()\n",
    "                \n",
    "                if url in self.visited:\n",
    "                    continue\n",
    "                    \n",
    "                self.visited.add(url)\n",
    "                html = await self.fetch_url(url)\n",
    "                \n",
    "                if html:\n",
    "                    links = self.extract_links(html, url)\n",
    "                    for link in links:\n",
    "                        if len(self.visited) + self.to_visit.qsize() < self.max_urls:\n",
    "                            await self.to_visit.put(link)\n",
    "                            \n",
    "            print(f\"Crawling complete. Visited {len(self.visited)} URLs\")\n",
    "            return self.visited\n",
    "\n",
    "    async def run_crawler_demo():\n",
    "        print(\"Starting web crawler demo\")\n",
    "        async with AsyncCrawler(\"https://docs.python.org/\", max_urls=5, rate_limit=1) as crawler:\n",
    "            visited_urls = await crawler.crawl()\n",
    "            print(\"\\nVisited URLs:\")\n",
    "            for i, url in enumerate(visited_urls, 1):\n",
    "                print(f\"{i}. {url}\")\n",
    "\n",
    "    # Run the crawler example if required packages are installed\n",
    "    try:\n",
    "        # Uncomment to run the crawler demo\n",
    "        # await run_crawler_demo()\n",
    "        pass\n",
    "    except NameError:\n",
    "        pass  # Skip if required packages aren't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Practices and Patterns\n",
    "\n",
    "### Error Handling in Asyncio\n",
    "\n",
    "Proper error handling is crucial in asynchronous code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def might_fail(success_rate=0.5):\n",
    "    import random\n",
    "    await asyncio.sleep(1)  # Simulate some work\n",
    "    if random.random() > success_rate:\n",
    "        raise ValueError(\"Operation failed\")\n",
    "    return \"Operation succeeded\"\n",
    "\n",
    "async def error_handling_demo():\n",
    "    # Method 1: Try/except around individual tasks\n",
    "    print(\"Method 1: Individual try/except:\")\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            result = await might_fail(0.3)\n",
    "            print(f\"Task {i}: {result}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Task {i} failed: {e}\")\n",
    "    \n",
    "    # Method 2: gather() with return_exceptions=True\n",
    "    print(\"\\nMethod 2: gather with return_exceptions=True:\")\n",
    "    tasks = [might_fail(0.3) for _ in range(3)]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"Task {i} failed: {result}\")\n",
    "        else:\n",
    "            print(f\"Task {i}: {result}\")\n",
    "    \n",
    "    # Method 3: Creating tasks and handling exceptions with callbacks\n",
    "    print(\"\\nMethod 3: Task callbacks:\")\n",
    "    \n",
    "    def handle_task_result(task):\n",
    "        try:\n",
    "            result = task.result()\n",
    "            print(f\"Task completed: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Task failed: {e}\")\n",
    "    \n",
    "    tasks = []\n",
    "    for i in range(3):\n",
    "        task = asyncio.create_task(might_fail(0.3))\n",
    "        task.add_done_callback(handle_task_result)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "await error_handling_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Asyncio Code\n",
    "\n",
    "Asyncio provides debugging options to help track down issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable debug mode\n",
    "def debug_demo():\n",
    "    \"\"\"This is just informational - you would run this in a Python script, not in a notebook\"\"\"\n",
    "    # In a Python script, you can enable debug mode:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    \n",
    "    # Method 1: Environment variable\n",
    "    # Set PYTHONASYNCIODEBUG=1 before running your script\n",
    "    \n",
    "    # Method 2: Using the event loop's debug mode\n",
    "    asyncio.get_event_loop().set_debug(True)\n",
    "    \n",
    "    # Method 3: In Python 3.7+\n",
    "    # asyncio.run(main(), debug=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debug features include:\n",
    "    # - More detailed logging\n",
    "    # - Warning about slow callbacks (>100ms)\n",
    "    # - Resource tracking (detect unclosed resources)\n",
    "    # - Exception handling improvements (more details about where exceptions occurred)\n",
    "\n",
    "# Tips for effective asyncio debugging:\n",
    "async def debugging_tips():\n",
    "    \"\"\"This is just for documentation - these are strategies you would apply in real code\"\"\"\n",
    "    # 1. Use meaningful task names\n",
    "    task = asyncio.create_task(long_running_task(\"Task A\", 3), name=\"fetch_user_data\")\n",
    "    \n",
    "    # 2. Use logging instead of print\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    logging.debug(\"Task started\")\n",
    "    \n",
    "    # 3. Run with debug mode in scripts\n",
    "    # asyncio.run(main(), debug=True)\n",
    "    \n",
    "    # 4. Use asyncio.current_task() to get the current task\n",
    "    current = asyncio.current_task()\n",
    "    assert current is not None, \"No current task found\"\n",
    "    print(f\"Current task: {current.get_name()}\")\n",
    "    \n",
    "    # 5. Use asyncio.all_tasks() to see all tasks\n",
    "    all_tasks = asyncio.all_tasks()\n",
    "    print(f\"Total tasks: {len(all_tasks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Asyncio Patterns\n",
    "\n",
    "Here are some common patterns you'll see with asyncio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Scatter-gather (process multiple items in parallel)\n",
    "async def process_item(item):\n",
    "    await asyncio.sleep(1)  # Simulate processing\n",
    "    return f\"Processed {item}\"\n",
    "\n",
    "async def scatter_gather_pattern(items):\n",
    "    tasks = [process_item(item) for item in items]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Pattern 2: Producer-Consumer with a queue\n",
    "async def producer_consumer_pattern(num_producers, num_consumers, num_items):\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    # Producer function\n",
    "    async def producer(producer_id, n_items):\n",
    "        for i in range(n_items):\n",
    "            item = f\"Producer {producer_id} - Item {i}\"\n",
    "            await queue.put(item)\n",
    "            await asyncio.sleep(0.1)  # Simulate production time\n",
    "        await queue.put(None)  # Sentinel to signal completion\n",
    "    \n",
    "    # Consumer function\n",
    "    async def consumer(consumer_id):\n",
    "        while True:\n",
    "            item = await queue.get()\n",
    "            if item is None:  # Check for sentinel\n",
    "                await queue.put(None)  # Put sentinel back for other consumers\n",
    "                break\n",
    "            print(f\"Consumer {consumer_id} processing {item}\")\n",
    "            await asyncio.sleep(0.5)  # Simulate consumption time\n",
    "            queue.task_done()\n",
    "    \n",
    "    # Create and start producers\n",
    "    producer_tasks = [asyncio.create_task(producer(i, num_items // num_producers)) \n",
    "                      for i in range(num_producers)]\n",
    "    \n",
    "    # Create and start consumers\n",
    "    consumer_tasks = [asyncio.create_task(consumer(i)) \n",
    "                     for i in range(num_consumers)]\n",
    "    \n",
    "    # Wait for all producers to finish\n",
    "    await asyncio.gather(*producer_tasks)\n",
    "    \n",
    "    # Wait for all consumers to finish\n",
    "    await asyncio.gather(*consumer_tasks)\n",
    "\n",
    "# Pattern 3: Throttled API calls with semaphores\n",
    "async def api_call(url, semaphore):\n",
    "    async with semaphore:  # Limit the number of concurrent API calls\n",
    "        print(f\"Calling API: {url}\")\n",
    "        await asyncio.sleep(1)  # Simulate API call\n",
    "        return f\"Result from {url}\"\n",
    "\n",
    "async def throttled_api_pattern(urls, max_concurrent=3):\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    tasks = [api_call(url, semaphore) for url in urls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Demonstrate a few of these patterns\n",
    "async def demonstrate_patterns():\n",
    "    print(\"Pattern 1: Scatter-Gather\")\n",
    "    items = ['item1', 'item2', 'item3', 'item4']\n",
    "    results = await scatter_gather_pattern(items)\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    print(\"\\nPattern 3: Throttled API Calls\")\n",
    "    urls = ['https://api.example.com/' + str(i) for i in range(1, 6)]\n",
    "    results = await throttled_api_pattern(urls, max_concurrent=2)\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    # Pattern 2 is more verbose, so let's run a small version\n",
    "    print(\"\\nPattern 2: Producer-Consumer\")\n",
    "    await producer_consumer_pattern(num_producers=2, num_consumers=2, num_items=4)\n",
    "\n",
    "await demonstrate_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Pitfalls to Avoid\n",
    "\n",
    "Here are some common mistakes when working with asyncio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall 1: Forgetting to await a coroutine\n",
    "async def pitfall_not_awaiting():\n",
    "    async def my_coro():\n",
    "        await asyncio.sleep(1)\n",
    "        print(\"Coroutine executed\")\n",
    "        return \"Result\"\n",
    "    \n",
    "    print(\"\\nPitfall 1: Forgetting to await a coroutine\")\n",
    "    # Wrong: This doesn't execute the coroutine, just creates a coroutine object\n",
    "    my_coro()  # This will show a warning in Python 3.8+\n",
    "    \n",
    "    # Correct: This executes the coroutine\n",
    "    await my_coro()\n",
    "\n",
    "# Pitfall 2: Blocking the event loop with CPU-bound or blocking operations\n",
    "async def pitfall_blocking_loop():\n",
    "    print(\"\\nPitfall 2: Blocking the event loop\")\n",
    "    \n",
    "    # Wrong: This blocks the event loop, preventing other coroutines from running\n",
    "    def heavy_computation():\n",
    "        print(\"Starting heavy computation...\")\n",
    "        # Simulate a CPU-intensive task\n",
    "        result = 0\n",
    "        for i in range(10_000_000):\n",
    "            result += i\n",
    "        print(\"Heavy computation finished\")\n",
    "        return result\n",
    "    \n",
    "    print(\"Wrong way (blocks the event loop):\")\n",
    "    start = time.time()\n",
    "    result = heavy_computation()  # This blocks the event loop!\n",
    "    print(f\"Time taken: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    # Correct: Use run_in_executor for CPU-bound tasks\n",
    "    print(\"\\nCorrect way (using executor):\")\n",
    "    start = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    result = await loop.run_in_executor(None, heavy_computation)\n",
    "    print(f\"Time taken: {time.time() - start:.2f}s\")\n",
    "\n",
    "# Pitfall 3: Not handling exceptions properly in tasks\n",
    "async def pitfall_unhandled_exceptions():\n",
    "    print(\"\\nPitfall 3: Not handling exceptions in tasks\")\n",
    "    \n",
    "    async def will_fail():\n",
    "        await asyncio.sleep(0.5)\n",
    "        raise ValueError(\"Task failed!\")\n",
    "    \n",
    "    # Wrong: Exceptions in tasks can be lost if not handled\n",
    "    print(\"Wrong way (exception will be lost):\")\n",
    "    task = asyncio.create_task(will_fail())\n",
    "    await asyncio.sleep(1)  # Wait long enough for the task to fail\n",
    "    \n",
    "    # Correct: Always await tasks to propagate exceptions\n",
    "    print(\"\\nCorrect way (catching the exception):\")\n",
    "    task = asyncio.create_task(will_fail())\n",
    "    try:\n",
    "        await task\n",
    "    except ValueError as e:\n",
    "        print(f\"Caught exception: {e}\")\n",
    "\n",
    "# Let's show these pitfalls\n",
    "async def show_pitfalls():\n",
    "    await pitfall_not_awaiting()\n",
    "    await pitfall_blocking_loop()\n",
    "    await pitfall_unhandled_exceptions()\n",
    "\n",
    "await show_pitfalls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed this comprehensive tutorial on Python's asyncio library. Let's recap what we've learned:\n",
    "\n",
    "1. **Asynchronous Programming Basics**\n",
    "   - Understanding the difference between synchronous and asynchronous code\n",
    "   - When to use asyncio (I/O-bound operations)\n",
    "\n",
    "2. **Core Asyncio Concepts**\n",
    "   - Coroutines and the `async`/`await` syntax\n",
    "   - Event loops\n",
    "   - Tasks and Futures\n",
    "\n",
    "3. **Advanced Features**\n",
    "   - Working with queues\n",
    "   - Synchronization primitives\n",
    "   - Error handling\n",
    "   - Timeouts\n",
    "\n",
    "4. **Practical Applications**\n",
    "   - Asynchronous HTTP requests\n",
    "   - File I/O operations\n",
    "   - Building a simple server\n",
    "   - Creating a web crawler\n",
    "\n",
    "5. **Best Practices and Common Patterns**\n",
    "   - Error handling strategies\n",
    "   - Debugging techniques\n",
    "   - Common patterns (scatter-gather, producer-consumer, throttling)\n",
    "   - Pitfalls to avoid\n",
    "\n",
    "Remember that asyncio is particularly powerful for I/O-bound applications but isn't suitable for CPU-bound tasks (use `multiprocessing` for those). With the knowledge gained from this tutorial, you should now be able to write efficient, concurrent code using Python's asyncio library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Resources\n",
    "\n",
    "To continue learning about asyncio:\n",
    "\n",
    "1. [Official asyncio documentation](https://docs.python.org/3/library/asyncio.html)\n",
    "2. [PEP 3156  Asynchronous IO Support](https://peps.python.org/pep-3156/)\n",
    "3. [Real Python's asyncio tutorials](https://realpython.com/async-io-python/)\n",
    "4. Popular asyncio libraries:\n",
    "   - [aiohttp](https://docs.aiohttp.org/)  HTTP client/server\n",
    "   - [FastAPI](https://fastapi.tiangolo.com/)  Web framework built on asyncio\n",
    "   - [asyncpg](https://magicstack.github.io/asyncpg/)  PostgreSQL client\n",
    "   - [aiomysql](https://aiomysql.readthedocs.io/)  MySQL client\n",
    "   - [motor](https://motor.readthedocs.io/)  MongoDB client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}