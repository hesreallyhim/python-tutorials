{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Python's asyncio\n",
    "\n",
    "This notebook provides a comprehensive tutorial on Python's `asyncio` library, designed to teach you asynchronous programming concepts from the ground up.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction to Asynchronous Programming](#1-introduction-to-asynchronous-programming)\n",
    "2. [Asyncio Basics](#2-asyncio-basics)\n",
    "3. [Working with Tasks and Futures](#3-working-with-tasks-and-futures)\n",
    "4. [Advanced Asyncio Concepts](#4-advanced-asyncio-concepts)\n",
    "5. [Practical Examples](#5-practical-examples)\n",
    "6. [Best Practices and Patterns](#6-best-practices-and-patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Asynchronous Programming\n",
    "\n",
    "### What is Asynchronous Programming?\n",
    "\n",
    "Asynchronous programming is a programming paradigm that allows multiple operations to be executed concurrently (not necessarily in parallel) without blocking the main execution thread. In contrast to synchronous programming where operations are executed sequentially, asynchronous programming enables non-blocking execution, making it ideal for I/O-bound operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous vs. Asynchronous: A Practical Example\n",
    "\n",
    "Let's compare synchronous and asynchronous approaches to understand the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Synchronous function to simulate an I/O operation\n",
    "def sync_io_operation(operation_name, duration):\n",
    "    print(f\"Starting {operation_name}...\")\n",
    "    time.sleep(duration)  # Blocking operation\n",
    "    print(f\"Finished {operation_name} after {duration}s\")\n",
    "    return f\"{operation_name} result\"\n",
    "\n",
    "# Simulating multiple synchronous operations\n",
    "def run_sync_operations():\n",
    "    start = time.time()\n",
    "    \n",
    "    result1 = sync_io_operation(\"Operation 1\", 2)\n",
    "    result2 = sync_io_operation(\"Operation 2\", 1)\n",
    "    result3 = sync_io_operation(\"Operation 3\", 3)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Total synchronous execution time: {end - start:.2f}s\")\n",
    "    return [result1, result2, result3]\n",
    "\n",
    "# Run the synchronous operations\n",
    "run_sync_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the same operations executed asynchronously using `asyncio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Asynchronous function to simulate an I/O operation\n",
    "async def async_io_operation(operation_name, duration):\n",
    "    print(f\"Starting {operation_name}...\")\n",
    "    await asyncio.sleep(duration)  # Non-blocking operation\n",
    "    print(f\"Finished {operation_name} after {duration}s\")\n",
    "    return f\"{operation_name} result\"\n",
    "\n",
    "# Simulating multiple asynchronous operations\n",
    "async def run_async_operations():\n",
    "    start = time.time()\n",
    "    \n",
    "    # Create tasks to run concurrently\n",
    "    task1 = asyncio.create_task(async_io_operation(\"Operation 1\", 2))\n",
    "    task2 = asyncio.create_task(async_io_operation(\"Operation 2\", 1))\n",
    "    task3 = asyncio.create_task(async_io_operation(\"Operation 3\", 3))\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = await asyncio.gather(task1, task2, task3)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Total asynchronous execution time: {end - start:.2f}s\")\n",
    "    return results\n",
    "\n",
    "# Run the asynchronous operations\n",
    "await run_async_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Asyncio\n",
    "\n",
    "Asyncio is particularly useful for:\n",
    "- I/O-bound operations (network requests, file operations)\n",
    "- Handling many concurrent connections (web servers, chat applications)\n",
    "- Operations that involve waiting (APIs with rate limits, scheduled tasks)\n",
    "\n",
    "It's less suitable for:\n",
    "- CPU-bound tasks (use multiprocessing instead)\n",
    "- Simple sequential operations with no waiting\n",
    "- Small scripts with minimal I/O operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Asyncio Basics\n",
    "\n",
    "### Coroutines and the `async`/`await` Syntax\n",
    "\n",
    "A coroutine is a specialized version of a Python generator function that can suspend and resume execution. They're created using the `async def` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a coroutine\n",
    "async def my_coroutine():\n",
    "    print(\"Coroutine started\")\n",
    "    await asyncio.sleep(1)  # Give up control and allow other coroutines to run\n",
    "    print(\"Coroutine resumed after 1 second\")\n",
    "    return \"Coroutine completed\"\n",
    "\n",
    "# This won't execute the coroutine, it just creates a coroutine object\n",
    "coro = my_coroutine()\n",
    "print(f\"Type of my_coroutine(): {type(coro)}\")\n",
    "\n",
    "# To actually run a coroutine, you need to schedule it on the event loop\n",
    "result = await my_coroutine()\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Event Loop\n",
    "\n",
    "The event loop is the core of every asyncio application. It's responsible for:\n",
    "- Scheduling and running asyncio tasks\n",
    "- Handling I/O events\n",
    "- Running subprocesses\n",
    "- Managing timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# In Jupyter notebooks, the event loop is already running (in IPython)\n",
    "# In regular Python scripts, you would manually run the loop like this:\n",
    "'''\n",
    "# For Python 3.7+\n",
    "asyncio.run(my_coroutine())  # Creates a new event loop and runs the coroutine\n",
    "\n",
    "# For older Python versions\n",
    "loop = asyncio.get_event_loop()\n",
    "result = loop.run_until_complete(my_coroutine())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Multiple Coroutines\n",
    "\n",
    "There are several ways to run multiple coroutines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def task1():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Task 1 completed\")\n",
    "    return \"Result 1\"\n",
    "\n",
    "async def task2():\n",
    "    await asyncio.sleep(0.5)\n",
    "    print(\"Task 2 completed\")\n",
    "    return \"Result 2\"\n",
    "\n",
    "# Method 1: Using asyncio.gather()\n",
    "print(\"Running tasks with asyncio.gather()\")\n",
    "results = await asyncio.gather(task1(), task2())\n",
    "print(f\"Results: {results}\")\n",
    "\n",
    "# Method 2: Creating and awaiting Tasks\n",
    "print(\"\\nRunning tasks with asyncio.create_task()\")\n",
    "t1 = asyncio.create_task(task1())\n",
    "t2 = asyncio.create_task(task2())\n",
    "await t1\n",
    "await t2\n",
    "print(f\"Results: {t1.result()}, {t2.result()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with Tasks and Futures\n",
    "\n",
    "### Tasks\n",
    "\n",
    "A Task is a wrapper around a coroutine that schedules it to run on the event loop. Tasks allow you to run coroutines concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def long_running_task(name, duration):\n",
    "    print(f\"{name} started\")\n",
    "    await asyncio.sleep(duration)\n",
    "    print(f\"{name} completed after {duration}s\")\n",
    "    return f\"{name} result\"\n",
    "\n",
    "async def manage_tasks():\n",
    "    # Create tasks\n",
    "    task_a = asyncio.create_task(long_running_task(\"Task A\", 3))\n",
    "    task_b = asyncio.create_task(long_running_task(\"Task B\", 2))\n",
    "    task_c = asyncio.create_task(long_running_task(\"Task C\", 1))\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    await asyncio.gather(task_a, task_b, task_c)\n",
    "    \n",
    "    print(f\"Task A result: {task_a.result()}\")\n",
    "    print(f\"Task B result: {task_b.result()}\")\n",
    "    print(f\"Task C result: {task_c.result()}\")\n",
    "\n",
    "await manage_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Cancellation\n",
    "\n",
    "You can cancel running tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cancellable_task():\n",
    "    try:\n",
    "        print(\"Task started\")\n",
    "        while True:  # Infinite loop\n",
    "            print(\"Working...\")\n",
    "            await asyncio.sleep(0.5)\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Task was cancelled!\")\n",
    "        raise  # Re-raise to properly handle cancellation\n",
    "\n",
    "async def cancel_after_delay(task, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    task.cancel()\n",
    "    print(f\"Cancellation request sent after {delay}s\")\n",
    "\n",
    "async def demo_cancellation():\n",
    "    task = asyncio.create_task(cancellable_task())\n",
    "    # Schedule the task to be cancelled after 2 seconds\n",
    "    asyncio.create_task(cancel_after_delay(task, 2))\n",
    "    \n",
    "    try:\n",
    "        await task\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Main function caught the cancellation\")\n",
    "\n",
    "await demo_cancellation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Futures\n",
    "\n",
    "A Future is a low-level awaitable object that represents an eventual result of an asynchronous operation. Tasks are a subclass of Future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_future_result(future, value, delay):\n",
    "    await asyncio.sleep(delay)\n",
    "    future.set_result(value)\n",
    "\n",
    "async def future_demo():\n",
    "    # Create a future\n",
    "    future = asyncio.Future()\n",
    "    \n",
    "    # Schedule a coroutine to set the future's result\n",
    "    asyncio.create_task(set_future_result(future, \"Future result\", 2))\n",
    "    \n",
    "    # Wait for the future to have a result\n",
    "    print(\"Waiting for future result...\")\n",
    "    result = await future\n",
    "    print(f\"Got result: {result}\")\n",
    "\n",
    "await future_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for Multiple Tasks\n",
    "\n",
    "You can wait for multiple tasks with different strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def wait_demo():\n",
    "    tasks = [\n",
    "        asyncio.create_task(long_running_task(\"Task X\", 3)),\n",
    "        asyncio.create_task(long_running_task(\"Task Y\", 1)),\n",
    "        asyncio.create_task(long_running_task(\"Task Z\", 2))\n",
    "    ]\n",
    "    \n",
    "    # Wait for the first task to complete\n",
    "    print(\"\\nWaiting for the first task to complete...\")\n",
    "    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "    \n",
    "    print(f\"\\n{len(done)} task(s) completed:\")\n",
    "    for task in done:\n",
    "        print(f\"  - {task.result()}\")\n",
    "        \n",
    "    print(f\"\\n{len(pending)} task(s) still pending\")\n",
    "    \n",
    "    # Wait for the remaining tasks\n",
    "    print(\"\\nWaiting for remaining tasks...\")\n",
    "    done, pending = await asyncio.wait(pending)\n",
    "    \n",
    "    print(f\"\\nAll tasks completed. Results:\")\n",
    "    for task in tasks:\n",
    "        print(f\"  - {task.result()}\")\n",
    "\n",
    "await wait_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Asyncio Concepts\n",
    "\n",
    "### Timeouts\n",
    "\n",
    "You can add timeouts to operations to prevent them from running too long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def potentially_slow_operation():\n",
    "    print(\"Slow operation started\")\n",
    "    await asyncio.sleep(5)  # Simulate a slow operation\n",
    "    print(\"Slow operation finished\")\n",
    "    return \"Operation result\"\n",
    "\n",
    "async def timeout_demo():\n",
    "    try:\n",
    "        # Set a 2-second timeout for the operation\n",
    "        result = await asyncio.wait_for(potentially_slow_operation(), timeout=2)\n",
    "        print(f\"Got result: {result}\")\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Operation timed out!\")\n",
    "\n",
    "await timeout_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asyncio Queues\n",
    "\n",
    "Asyncio provides queue implementations for coordinating between producer and consumer coroutines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def producer(queue, name, items):\n",
    "    for i in range(items):\n",
    "        item = f\"{name} item {i}\"\n",
    "        await queue.put(item)\n",
    "        print(f\"{name} produced: {item}\")\n",
    "        await asyncio.sleep(0.5)\n",
    "    print(f\"{name} finished producing\")\n",
    "\n",
    "async def consumer(queue, name, items_to_process):\n",
    "    for _ in range(items_to_process):\n",
    "        item = await queue.get()\n",
    "        print(f\"{name} consumed: {item}\")\n",
    "        queue.task_done()\n",
    "        await asyncio.sleep(1)  # Simulate processing time\n",
    "    print(f\"{name} finished consuming\")\n",
    "\n",
    "async def queue_demo():\n",
    "    # Create a queue\n",
    "    queue = asyncio.Queue(maxsize=5)  # Limit queue size to 5 items\n",
    "    \n",
    "    # Create tasks for producers and consumers\n",
    "    producer_tasks = [\n",
    "        asyncio.create_task(producer(queue, \"Producer 1\", 4)),\n",
    "        asyncio.create_task(producer(queue, \"Producer 2\", 3))\n",
    "    ]\n",
    "    \n",
    "    consumer_tasks = [\n",
    "        asyncio.create_task(consumer(queue, \"Consumer 1\", 3)),\n",
    "        asyncio.create_task(consumer(queue, \"Consumer 2\", 4))\n",
    "    ]\n",
    "    \n",
    "    # Wait for all producers to finish\n",
    "    await asyncio.gather(*producer_tasks)\n",
    "    \n",
    "    # Wait for the queue to be fully processed\n",
    "    await queue.join()\n",
    "    \n",
    "    # Wait for all consumers to finish\n",
    "    await asyncio.gather(*consumer_tasks)\n",
    "    \n",
    "    print(\"Queue demo completed\")\n",
    "\n",
    "await queue_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronization Primitives\n",
    "\n",
    "Asyncio provides synchronization primitives similar to the ones in the `threading` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def worker(lock, worker_id, shared_resource):\n",
    "    print(f\"Worker {worker_id} is waiting for the lock\")\n",
    "    async with lock:  # Acquire and release the lock automatically\n",
    "        print(f\"Worker {worker_id} acquired the lock\")\n",
    "        # Simulate working with a shared resource\n",
    "        shared_resource.append(worker_id)\n",
    "        print(f\"Worker {worker_id} updated shared resource: {shared_resource}\")\n",
    "        await asyncio.sleep(1)  # Simulate some work\n",
    "    print(f\"Worker {worker_id} released the lock\")\n",
    "\n",
    "async def lock_demo():\n",
    "    # Create a lock\n",
    "    lock = asyncio.Lock()\n",
    "    shared_resource = []\n",
    "    \n",
    "    # Create and run multiple workers concurrently\n",
    "    workers = [worker(lock, i, shared_resource) for i in range(3)]\n",
    "    await asyncio.gather(*workers)\n",
    "    \n",
    "    print(f\"Final shared resource: {shared_resource}\")\n",
    "\n",
    "await lock_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Examples\n",
    "\n",
    "### Asynchronous Web Requests\n",
    "\n",
    "Let's use `aiohttp` to make concurrent web requests (install with `pip install aiohttp` if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import aiohttp\n",
    "except ImportError:\n",
    "    print(\"aiohttp is not installed. Please install it with:\")\n",
    "    print(\"pip install aiohttp\")\n",
    "    print(\"\\nFor now, we'll skip this example.\")\n",
    "else:\n",
    "    async def fetch_url(session, url):\n",
    "        print(f\"Fetching {url}\")\n",
    "        async with session.get(url) as response:\n",
    "            if response.status != 200:\n",
    "                return f\"Error: {response.status} for {url}\"\n",
    "            data = await response.text()\n",
    "            return f\"Fetched {len(data)} bytes from {url}\"\n",
    "\n",
    "    async def fetch_multiple_urls():\n",
    "        urls = [\n",
    "            \"https://example.com\",\n",
    "            \"https://python.org\",\n",
    "            \"https://docs.python.org/\"\n",
    "        ]\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [fetch_url(session, url) for url in urls]\n",
    "            results = await asyncio.gather(*tasks)\n",
    "            \n",
    "            for i, result in enumerate(results):\n",
    "                print(f\"Result {i+1}: {result}\")\n",
    "\n",
    "    # Run the example if aiohttp is installed\n",
    "    try:\n",
    "        await fetch_multiple_urls()\n",
    "    except NameError:\n",
    "        pass  # Skip if aiohttp isn't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File I/O with aiofiles\n",
    "\n",
    "Let's use `aiofiles` for asynchronous file operations (install with `pip install aiofiles` if needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import aiofiles\n",
    "except ImportError:\n",
    "    print(\"aiofiles is not installed. Please install it with:\")\n",
    "    print(\"pip install aiofiles\")\n",
    "    print(\"\\nFor now, we'll skip this example.\")\n",
    "else:\n",
    "    async def write_file(filename, content):\n",
    "        print(f\"Writing to {filename}\")\n",
    "        async with aiofiles.open(filename, 'w') as file:\n",
    "            await file.write(content)\n",
    "        print(f\"Finished writing to {filename}\")\n",
    "\n",
    "    async def read_file(filename):\n",
    "        print(f\"Reading from {filename}\")\n",
    "        async with aiofiles.open(filename, 'r') as file:\n",
    "            content = await file.read()\n",
    "        print(f\"Read {len(content)} bytes from {filename}\")\n",
    "        return content\n",
    "\n",
    "    async def file_io_demo():\n",
    "        # Write files concurrently\n",
    "        write_tasks = [\n",
    "            write_file('asyncio_demo_1.txt', 'This is file 1 content\\n' * 1000),\n",
    "            write_file('asyncio_demo_2.txt', 'This is file 2 content\\n' * 1000),\n",
    "            write_file('asyncio_demo_3.txt', 'This is file 3 content\\n' * 1000)\n",
    "        ]\n",
    "        await asyncio.gather(*write_tasks)\n",
    "        \n",
    "        # Read files concurrently\n",
    "        read_tasks = [\n",
    "            read_file('asyncio_demo_1.txt'),\n",
    "            read_file('asyncio_demo_2.txt'),\n",
    "            read_file('asyncio_demo_3.txt')\n",
    "        ]\n",
    "        results = await asyncio.gather(*read_tasks)\n",
    "        \n",
    "        # Clean up demo files (optional)\n",
    "        import os\n",
    "        for i in range(1, 4):\n",
    "            os.remove(f'asyncio_demo_{i}.txt')\n",
    "            \n",
    "        print(\"File I/O demo completed\")\n",
    "\n",
    "    # Run the example if aiofiles is installed\n",
    "    try:\n",
    "        await file_io_demo()\n",
    "    except NameError:\n",
    "        pass  # Skip if aiofiles isn't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Simple Asynchronous Server\n",
    "\n",
    "Let's build a very simple echo server using asyncio streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_client(reader, writer):\n",
    "    # Get client address\n",
    "    addr = writer.get_extra_info('peername')\n",
    "    print(f\"Client connected: {addr}\")\n",
    "    \n",
    "    while True:\n",
    "        # Read data from the client\n",
    "        data = await reader.read(100)\n",
    "        message = data.decode()\n",
    "        \n",
    "        if not data:  # Client disconnected\n",
    "            break\n",
    "            \n",
    "        print(f\"Received from {addr}: {message.strip()}\")\n",
    "        \n",
    "        # Echo the message back to the client\n",
    "        response = f\"Echo: {message}\"\n",
    "        writer.write(response.encode())\n",
    "        await writer.drain()\n",
    "        \n",
    "    # Close the connection\n",
    "    print(f\"Client disconnected: {addr}\")\n",
    "    writer.close()\n",
    "    await writer.wait_closed()\n",
    "\n",
    "async def run_server():\n",
    "    server = await asyncio.start_server(\n",
    "        handle_client, '127.0.0.1', 8888)\n",
    "    \n",
    "    # Get server address\n",
    "    addr = server.sockets[0].getsockname()\n",
    "    print(f\"Server running on {addr}\")\n",
    "    \n",
    "    print(\"To test the server:\")\n",
    "    print(\"1. Open another terminal\")\n",
    "    print(\"2. Use: telnet 127.0.0.1 8888\")\n",
    "    print(\"3. Type messages and see them echoed back\")\n",
    "    print(\"4. Press Ctrl+C here to stop the server\")\n",
    "    \n",
    "    try:\n",
    "        async with server:\n",
    "            # This will keep the server running until cancelled\n",
    "            await server.serve_forever()\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Server stopped\")\n",
    "\n",
    "# Uncomment to run the server (note: this will block the notebook until cancelled)\n",
    "# await run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating a Real-world Application: Web Crawler\n",
    "\n",
    "Let's build a simple asynchronous web crawler that respects rate limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import aiohttp\n",
    "    from bs4 import BeautifulSoup\n",
    "except ImportError:\n",
    "    print(\"Required packages not installed. Please install them with:\")\n",
    "    print(\"pip install aiohttp beautifulsoup4\")\n",
    "    print(\"\\nSkipping this example.\")\n",
    "else:\n",
    "    class AsyncCrawler:\n",
    "        def __init__(self, base_url, max_urls=10, rate_limit=1):\n",
    "            self.base_url = base_url\n",
    "            self.to_visit = asyncio.Queue()\n",
    "            self.visited = set()\n",
    "            self.max_urls = max_urls\n",
    "            self.rate_limit = rate_limit  # Seconds between requests\n",
    "            self.session = None\n",
    "            self.rate_limiter = asyncio.Semaphore(1)  # Only 1 request at a time\n",
    "            \n",
    "        async def __aenter__(self):\n",
    "            self.session = aiohttp.ClientSession()\n",
    "            await self.to_visit.put(self.base_url)\n",
    "            return self\n",
    "            \n",
    "        async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "            await self.session.close()\n",
    "            \n",
    "        async def fetch_url(self, url):\n",
    "            async with self.rate_limiter:\n",
    "                print(f\"Fetching: {url}\")\n",
    "                try:\n",
    "                    async with self.session.get(url) as response:\n",
    "                        if response.status != 200:\n",
    "                            print(f\"Error: {response.status} for {url}\")\n",
    "                            return None\n",
    "                            \n",
    "                        html = await response.text()\n",
    "                        print(f\"Fetched {len(html)} bytes from {url}\")\n",
    "                        # Respect rate limit\n",
    "                        await asyncio.sleep(self.rate_limit)\n",
    "                        return html\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching {url}: {e}\")\n",
    "                    return None\n",
    "                    \n",
    "        def extract_links(self, html, url):\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            links = set()\n",
    "            \n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                \n",
    "                # Handle relative URLs\n",
    "                if href.startswith('/'):\n",
    "                    href = f\"{self.base_url.rstrip('/')}{href}\"\n",
    "                    \n",
    "                # Only follow links from the same domain\n",
    "                if href.startswith(self.base_url) and href not in self.visited:\n",
    "                    links.add(href)\n",
    "                    \n",
    "            print(f\"Found {len(links)} new links on {url}\")\n",
    "            return links\n",
    "            \n",
    "        async def crawl(self):\n",
    "            while len(self.visited) < self.max_urls:\n",
    "                if self.to_visit.empty():\n",
    "                    print(\"No more URLs to visit\")\n",
    "                    break\n",
    "                    \n",
    "                url = await self.to_visit.get()\n",
    "                \n",
    "                if url in self.visited:\n",
    "                    continue\n",
    "                    \n",
    "                self.visited.add(url)\n",
    "                html = await self.fetch_url(url)\n",
    "                \n",
    "                if html:\n",
    "                    links = self.extract_links(html, url)\n",
    "                    for link in links:\n",
    "                        if len(self.visited) + self.to_visit.qsize() < self.max_urls:\n",
    "                            await self.to_visit.put(link)\n",
    "                            \n",
    "            print(f\"Crawling complete. Visited {len(self.visited)} URLs\")\n",
    "            return self.visited\n",
    "\n",
    "    async def run_crawler_demo():\n",
    "        print(\"Starting web crawler demo\")\n",
    "        async with AsyncCrawler(\"https://docs.python.org/\", max_urls=5, rate_limit=1) as crawler:\n",
    "            visited_urls = await crawler.crawl()\n",
    "            print(\"\\nVisited URLs:\")\n",
    "            for i, url in enumerate(visited_urls, 1):\n",
    "                print(f\"{i}. {url}\")\n",
    "\n",
    "    # Run the crawler example if required packages are installed\n",
    "    try:\n",
    "        # Uncomment to run the crawler demo\n",
    "        # await run_crawler_demo()\n",
    "        pass\n",
    "    except NameError:\n",
    "        pass  # Skip if required packages aren't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Practices and Patterns\n",
    "\n",
    "### Error Handling in Asyncio\n",
    "\n",
    "Proper error handling is crucial in asynchronous code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def might_fail(success_rate=0.5):\n",
    "    import random\n",
    "    await asyncio.sleep(1)  # Simulate some work\n",
    "    if random.random() > success_rate:\n",
    "        raise ValueError(\"Operation failed\")\n",
    "    return \"Operation succeeded\"\n",
    "\n",
    "async def error_handling_demo():\n",
    "    # Method 1: Try/except around individual tasks\n",
    "    print(\"Method 1: Individual try/except:\")\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            result = await might_fail(0.3)\n",
    "            print(f\"Task {i}: {result}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Task {i} failed: {e}\")\n",
    "    \n",
    "    # Method 2: gather() with return_exceptions=True\n",
    "    print(\"\\nMethod 2: gather with return_exceptions=True:\")\n",
    "    tasks = [might_fail(0.3) for _ in range(3)]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"Task {i} failed: {result}\")\n",
    "        else:\n",
    "            print(f\"Task {i}: {result}\")\n",
    "    \n",
    "    # Method 3: Creating tasks and handling exceptions with callbacks\n",
    "    print(\"\\nMethod 3: Task callbacks:\")\n",
    "    \n",
    "    def handle_task_result(task):\n",
    "        try:\n",
    "            result = task.result()\n",
    "            print(f\"Task completed: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Task failed: {e}\")\n",
    "    \n",
    "    tasks = []\n",
    "    for i in range(3):\n",
    "        task = asyncio.create_task(might_fail(0.3))\n",
    "        task.add_done_callback(handle_task_result)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "await error_handling_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Asyncio Code\n",
    "\n",
    "Asyncio provides debugging options to help track down issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable debug mode\n",
    "def debug_demo():\n",
    "    \"\"\"This is just informational - you would run this in a Python script, not in a notebook\"\"\"\n",
    "    # In a Python script, you can enable debug mode:\n",
    "    \"\"\"\n",
    "    import asyncio\n",
    "    \n",
    "    # Method 1: Environment variable\n",
    "    # Set PYTHONASYNCIODEBUG=1 before running your script\n",
    "    \n",
    "    # Method 2: Using the event loop's debug mode\n",
    "    asyncio.get_event_loop().set_debug(True)\n",
    "    \n",
    "    # Method 3: In Python 3.7+\n",
    "    # asyncio.run(main(), debug=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debug features include:\n",
    "    # - More detailed logging\n",
    "    # - Warning about slow callbacks (>100ms)\n",
    "    # - Resource tracking (detect unclosed resources)\n",
    "    # - Exception handling improvements (more details about where exceptions occurred)\n",
    "\n",
    "# Tips for effective asyncio debugging:\n",
    "async def debugging_tips():\n",
    "    \"\"\"This is just for documentation - these are strategies you would apply in real code\"\"\"\n",
    "    # 1. Use meaningful task names\n",
    "    task = asyncio.create_task(long_running_task(\"Task A\", 3), name=\"fetch_user_data\")\n",
    "    \n",
    "    # 2. Use logging instead of print\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    logging.debug(\"Task started\")\n",
    "    \n",
    "    # 3. Run with debug mode in scripts\n",
    "    # asyncio.run(main(), debug=True)\n",
    "    \n",
    "    # 4. Use asyncio.current_task() to get the current task\n",
    "    current = asyncio.current_task()\n",
    "    print(f\"Current task: {current.get_name()}\")\n",
    "    \n",
    "    # 5. Use asyncio.all_tasks() to see all tasks\n",
    "    all_tasks = asyncio.all_tasks()\n",
    "    print(f\"Total tasks: {len(all_tasks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Asyncio Patterns\n",
    "\n",
    "Here are some common patterns you'll see with asyncio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Scatter-gather (process multiple items in parallel)\n",
    "async def process_item(item):\n",
    "    await asyncio.sleep(1)  # Simulate processing\n",
    "    return f\"Processed {item}\"\n",
    "\n",
    "async def scatter_gather_pattern(items):\n",
    "    tasks = [process_item(item) for item in items]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Pattern 2: Producer-Consumer with a queue\n",
    "async def producer_consumer_pattern(num_producers, num_consumers, num_items):\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    # Producer function\n",
    "    async def producer(producer_id, n_items):\n",
    "        for i in range(n_items):\n",
    "            item = f\"Producer {producer_id} - Item {i}\"\n",
    "            await queue.put(item)\n",
    "            await asyncio.sleep(0.1)  # Simulate production time\n",
    "        await queue.put(None)  # Sentinel to signal completion\n",
    "    \n",
    "    # Consumer function\n",
    "    async def consumer(consumer_id):\n",
    "        while True:\n",
    "            item = await queue.get()\n",
    "            if item is None:  # Check for sentinel\n",
    "                await queue.put(None)  # Put sentinel back for other consumers\n",
    "                break\n",
    "            print(f\"Consumer {consumer_id} processing {item}\")\n",
    "            await asyncio.sleep(0.5)  # Simulate consumption time\n",
    "            queue.task_done()\n",
    "    \n",
    "    # Create and start producers\n",
    "    producer_tasks = [asyncio.create_task(producer(i, num_items // num_producers)) \n",
    "                      for i in range(num_producers)]\n",
    "    \n",
    "    # Create and start consumers\n",
    "    consumer_tasks = [asyncio.create_task(consumer(i)) \n",
    "                     for i in range(num_consumers)]\n",
    "    \n",
    "    # Wait for all producers to finish\n",
    "    await asyncio.gather(*producer_tasks)\n",
    "    \n",
    "    # Wait for all consumers to finish\n",
    "    await asyncio.gather(*consumer_tasks)\n",
    "\n",
    "# Pattern 3: Throttled API calls with semaphores\n",
    "async def api_call(url, semaphore):\n",
    "    async with semaphore:  # Limit the number of concurrent API calls\n",
    "        print(f\"Calling API: {url}\")\n",
    "        await asyncio.sleep(1)  # Simulate API call\n",
    "        return f\"Result from {url}\"\n",
    "\n",
    "async def throttled_api_pattern(urls, max_concurrent=3):\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    tasks = [api_call(url, semaphore) for url in urls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Demonstrate a few of these patterns\n",
    "async def demonstrate_patterns():\n",
    "    print(\"Pattern 1: Scatter-Gather\")\n",
    "    items = ['item1', 'item2', 'item3', 'item4']\n",
    "    results = await scatter_gather_pattern(items)\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    print(\"\\nPattern 3: Throttled API Calls\")\n",
    "    urls = ['https://api.example.com/' + str(i) for i in range(1, 6)]\n",
    "    results = await throttled_api_pattern(urls, max_concurrent=2)\n",
    "    print(f\"Results: {results}\")\n",
    "    \n",
    "    # Pattern 2 is more verbose, so let's run a small version\n",
    "    print(\"\\nPattern 2: Producer-Consumer\")\n",
    "    await producer_consumer_pattern(num_producers=2, num_consumers=2, num_items=4)\n",
    "\n",
    "await demonstrate_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Pitfalls to Avoid\n",
    "\n",
    "Here are some common mistakes when working with asyncio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall 1: Forgetting to await a coroutine\n",
    "async def pitfall_not_awaiting():\n",
    "    async def my_coro():\n",
    "        await asyncio.sleep(1)\n",
    "        print(\"Coroutine executed\")\n",
    "        return \"Result\"\n",
    "    \n",
    "    print(\"\\nPitfall 1: Forgetting to await a coroutine\")\n",
    "    # Wrong: This doesn't execute the coroutine, just creates a coroutine object\n",
    "    my_coro()  # This will show a warning in Python 3.8+\n",
    "    \n",
    "    # Correct: This executes the coroutine\n",
    "    await my_coro()\n",
    "\n",
    "# Pitfall 2: Blocking the event loop with CPU-bound or blocking operations\n",
    "async def pitfall_blocking_loop():\n",
    "    print(\"\\nPitfall 2: Blocking the event loop\")\n",
    "    \n",
    "    # Wrong: This blocks the event loop, preventing other coroutines from running\n",
    "    def heavy_computation():\n",
    "        print(\"Starting heavy computation...\")\n",
    "        # Simulate a CPU-intensive task\n",
    "        result = 0\n",
    "        for i in range(10_000_000):\n",
    "            result += i\n",
    "        print(\"Heavy computation finished\")\n",
    "        return result\n",
    "    \n",
    "    print(\"Wrong way (blocks the event loop):\")\n",
    "    start = time.time()\n",
    "    result = heavy_computation()  # This blocks the event loop!\n",
    "    print(f\"Time taken: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    # Correct: Use run_in_executor for CPU-bound tasks\n",
    "    print(\"\\nCorrect way (using executor):\")\n",
    "    start = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    result = await loop.run_in_executor(None, heavy_computation)\n",
    "    print(f\"Time taken: {time.time() - start:.2f}s\")\n",
    "\n",
    "# Pitfall 3: Not handling exceptions properly in tasks\n",
    "async def pitfall_unhandled_exceptions():\n",
    "    print(\"\\nPitfall 3: Not handling exceptions in tasks\")\n",
    "    \n",
    "    async def will_fail():\n",
    "        await asyncio.sleep(0.5)\n",
    "        raise ValueError(\"Task failed!\")\n",
    "    \n",
    "    # Wrong: Exceptions in tasks can be lost if not handled\n",
    "    print(\"Wrong way (exception will be lost):\")\n",
    "    task = asyncio.create_task(will_fail())\n",
    "    await asyncio.sleep(1)  # Wait long enough for the task to fail\n",
    "    \n",
    "    # Correct: Always await tasks to propagate exceptions\n",
    "    print(\"\\nCorrect way (catching the exception):\")\n",
    "    task = asyncio.create_task(will_fail())\n",
    "    try:\n",
    "        await task\n",
    "    except ValueError as e:\n",
    "        print(f\"Caught exception: {e}\")\n",
    "\n",
    "# Let's show these pitfalls\n",
    "async def show_pitfalls():\n",
    "    await pitfall_not_awaiting()\n",
    "    await pitfall_blocking_loop()\n",
    "    await pitfall_unhandled_exceptions()\n",
    "\n",
    "await show_pitfalls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed this comprehensive tutorial on Python's asyncio library. Let's recap what we've learned:\n",
    "\n",
    "1. **Asynchronous Programming Basics**\n",
    "   - Understanding the difference between synchronous and asynchronous code\n",
    "   - When to use asyncio (I/O-bound operations)\n",
    "\n",
    "2. **Core Asyncio Concepts**\n",
    "   - Coroutines and the `async`/`await` syntax\n",
    "   - Event loops\n",
    "   - Tasks and Futures\n",
    "\n",
    "3. **Advanced Features**\n",
    "   - Working with queues\n",
    "   - Synchronization primitives\n",
    "   - Error handling\n",
    "   - Timeouts\n",
    "\n",
    "4. **Practical Applications**\n",
    "   - Asynchronous HTTP requests\n",
    "   - File I/O operations\n",
    "   - Building a simple server\n",
    "   - Creating a web crawler\n",
    "\n",
    "5. **Best Practices and Common Patterns**\n",
    "   - Error handling strategies\n",
    "   - Debugging techniques\n",
    "   - Common patterns (scatter-gather, producer-consumer, throttling)\n",
    "   - Pitfalls to avoid\n",
    "\n",
    "Remember that asyncio is particularly powerful for I/O-bound applications but isn't suitable for CPU-bound tasks (use `multiprocessing` for those). With the knowledge gained from this tutorial, you should now be able to write efficient, concurrent code using Python's asyncio library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Resources\n",
    "\n",
    "To continue learning about asyncio:\n",
    "\n",
    "1. [Official asyncio documentation](https://docs.python.org/3/library/asyncio.html)\n",
    "2. [PEP 3156 – Asynchronous IO Support](https://peps.python.org/pep-3156/)\n",
    "3. [Real Python's asyncio tutorials](https://realpython.com/async-io-python/)\n",
    "4. Popular asyncio libraries:\n",
    "   - [aiohttp](https://docs.aiohttp.org/) – HTTP client/server\n",
    "   - [FastAPI](https://fastapi.tiangolo.com/) – Web framework built on asyncio\n",
    "   - [asyncpg](https://magicstack.github.io/asyncpg/) – PostgreSQL client\n",
    "   - [aiomysql](https://aiomysql.readthedocs.io/) – MySQL client\n",
    "   - [motor](https://motor.readthedocs.io/) – MongoDB client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}